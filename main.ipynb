{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Estimation task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DEVELOPMENT = \"Dataset/development.csv\"\n",
    "FILE_EVALUATION = \"Dataset/evaluation.csv\"\n",
    "AUDIOS_DEVELOPMENT = \"Dataset/audios_development/\"\n",
    "AUDIOS_EVALUATION = \"Dataset/audios_evaluation/\"\n",
    "\n",
    "precisionLog = {\n",
    "    'mean_pitch':2, \n",
    "    'max_pitch':2, \n",
    "    'min_pitch':3, \n",
    "    'jitter':2, \n",
    "    'shimmer':2, \n",
    "    'energy':1, \n",
    "    'zcr_mean':2, \n",
    "    'spectral_centroid_mean':2,\n",
    "    'tempo':3,\n",
    "    'hnr':0\n",
    "}\n",
    "\n",
    "precisionLinear = {\n",
    "    'mean_pitch':-1, \n",
    "    'max_pitch':-2, \n",
    "    'min_pitch':0, \n",
    "    'jitter':3, \n",
    "    'shimmer':3, \n",
    "    'energy':3, \n",
    "    'zcr_mean':2, \n",
    "    'spectral_centroid_mean':-2,\n",
    "    'tempo':3,\n",
    "    'hnr':0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_original_df = pd.read_csv(FILE_DEVELOPMENT, header=0, index_col=0)\n",
    "eval_original_df = pd.read_csv(FILE_EVALUATION, header=0, index_col=0)\n",
    "\n",
    "audio_dev = os.listdir(AUDIOS_DEVELOPMENT)\n",
    "audio_eval = os.listdir(AUDIOS_EVALUATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(dev_original_df.head())\n",
    "\n",
    "display(f\"Total number of nan in development: {dev_original_df.isna().sum().sum()}\")\n",
    "display(f\"Total number of nan in evaluation: {eval_original_df.isna().sum().sum()}\")\n",
    "\n",
    "desc_dev_df = dev_original_df.describe()\n",
    "desc_eval_df = eval_original_df.describe()\n",
    "\n",
    "sampling_rate = dev_original_df['sampling_rate'].iloc[0]\n",
    "\n",
    "# display(desc_dev_df.loc['std', 'sampling_rate'])\n",
    "# display(desc_eval_df.loc['std', 'sampling_rate'])\n",
    "\n",
    "dev_df = dev_original_df.drop('sampling_rate', axis=1)\n",
    "eval_df = eval_original_df.drop('sampling_rate', axis=1)\n",
    "\n",
    "ages_df = dev_df[['age']]\n",
    "path_dev_df = dev_df[['path']]\n",
    "path_eval_df = eval_df[['path']]\n",
    "\n",
    "dev_df = dev_df.drop(['path'], axis=1)\n",
    "eval_df = eval_df.drop('path', axis=1)\n",
    "\n",
    "display(dev_df.head())\n",
    "display(eval_df.head())\n",
    "\n",
    "# display(path_dev_df)\n",
    "# display(path_eval_df)\n",
    "display(dev_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = eval_df['num_words'].value_counts\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enticity_df = dev_df['ethnicity'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "median_et = enticity_df.median()\n",
    "display(enticity_df[enticity_df == 1].shape)\n",
    "display(enticity_df.head(20))\n",
    "display(enticity_df.tail(10))\n",
    "# enticity_df[enticity_df > median_et].plot()\n",
    "\n",
    "etnie_chosen = sorted(list(set(enticity_df[enticity_df > median_et].index)))\n",
    "display(etnie_chosen)\n",
    "display(etnie_chosen.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(dev_df)\n",
    "def encode_ethnicity(X_df, ethnie):\n",
    "    etna = pd.DataFrame(1, columns=ethnie, index=X_df.index)\n",
    "\n",
    "    aggregated_ethnicity_df = X_df.copy()\n",
    "    aggregated_ethnicity_df.loc[~(aggregated_ethnicity_df['ethnicity'].isin(ethnie)), 'ethnicity'] = 'others'\n",
    "\n",
    "    for etnia in ethnie:\n",
    "        aggregated_ethnicity_df.loc[aggregated_ethnicity_df['ethnicity'] == etnia, etnia] = etna[etnia]\n",
    "\n",
    "        # aggregated_ethnicity_df.loc[aggregated_ethnicity_df['ethnicity'] == etnia, etnia] = 1\n",
    "        aggregated_ethnicity_df.loc[~(aggregated_ethnicity_df['ethnicity'] == etnia), etnia] = 0\n",
    "\n",
    "    # encoded_ethnicity = pd.get_dummies(aggregated_ethnicity_df['ethnicity'], dtype=int)\n",
    "\n",
    "    try:\n",
    "        aggregated_ethnicity_df = aggregated_ethnicity_df.drop(columns=['ethnicity'], axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    return aggregated_ethnicity_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenderMapper = {\n",
    "    'male': 1,\n",
    "    'female': -1\n",
    "}\n",
    "\n",
    "def encode_gender(X_df:pd.DataFrame, mapper):\n",
    "    encoded_df = X_df.copy()\n",
    "    for gender, value in mapper.items():\n",
    "        encoded_df.loc[encoded_df['gender'] == gender, 'gender'] = value\n",
    "\n",
    "    encoded_df.loc[encoded_df['gender'] == 'famale', 'gender'] = -1\n",
    "\n",
    "    encoded_df['gender'] = encoded_df['gender'].astype(float)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(encoded_gender_etnicity_df['tempo'])\n",
    "\n",
    "def encode_tempo(X_df):\n",
    "    encoded_df = X_df.copy()\n",
    "    encoded_df['tempo'] = encoded_df['tempo'].map(lambda x: float(x.strip('[').strip(']')))\n",
    "    return encoded_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(eval_df.loc[eval_df['ethnicity'].isin(etnie_chosen), 'ethnicity'].value_counts())\n",
    "\n",
    "step1_dev_df = encode_ethnicity(dev_df, etnie_chosen)\n",
    "step1_eval_df = encode_ethnicity(eval_df, etnie_chosen)\n",
    "\n",
    "display(dev_df.head(5))\n",
    "# display(eval_df.head(5))\n",
    "\n",
    "# step1_eval_df = encode_ethnicity(eval_df, etnie_chosen)\n",
    "\n",
    "# display(step1_dev_df.head())\n",
    "# display(step1_eval_df.head())\n",
    "\n",
    "# step1_eval_df['gender'].value_counts()\n",
    "\n",
    "step2_dev_df = encode_gender(step1_dev_df, GenderMapper)\n",
    "step2_eval_df = encode_gender(step1_eval_df, GenderMapper)\n",
    "\n",
    "display(step2_dev_df.head(5))\n",
    "# display(step2_eval_df.head(5))\n",
    "\n",
    "step3_dev_df = encode_tempo(step2_dev_df)\n",
    "step3_eval_df = encode_tempo(step2_eval_df)\n",
    "\n",
    "display(step3_dev_df.head(5))\n",
    "# display(step3_eval_df.head(5))\n",
    "\n",
    "# step3_dev_df = step3_dev_df.drop(columns=['ethnicity'], axis=1)\n",
    "# step3_eval_df = step3_eval_df.drop(columns=['ethnicity'], axis=1)\n",
    "\n",
    "# display(step3_dev_df.head(5))\n",
    "\n",
    "# display(step3_eval_df[step3_eval_df['yoruba'] == 1])\n",
    "# display(eval_df.loc[75, :])\n",
    "\n",
    "display(step3_dev_df.describe())\n",
    "step3_dev_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior analysis and $log_{10}$ scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colors(values:pd.Series, label:str, use_continous:bool=False, \n",
    "                  cmap_continuous = cm.viridis, cmap_discrete = cm.rainbow):\n",
    "    if use_continous:\n",
    "        cmap_ = cmap_continuous\n",
    "        # Alternative normalization without iterquartile ranges:\n",
    "        norm = plt.Normalize(vmin=np.min(values), vmax=np.max(values)) \n",
    "        \n",
    "        mappable = cm.ScalarMappable(norm=norm, cmap=cmap_)\n",
    "        handles = None\n",
    "    else:\n",
    "        cmap_ = cmap_discrete\n",
    "        norm = plt.Normalize(vmin=np.min(values), vmax=np.max(values)) \n",
    "        \n",
    "        mappable = None\n",
    "        handles = [\n",
    "            Line2D(\n",
    "                [0], [0], marker='o', color='none', linestyle='None', \n",
    "                markeredgewidth=0, markerfacecolor=cmap_(norm(val)), \n",
    "                markersize=10, label=label\n",
    "            ) for label, val in GenderMapper.items()\n",
    "        ]\n",
    "\n",
    "    return cmap_, norm, mappable, handles \n",
    "\n",
    "def round_column(data: pd.DataFrame, col: str, isLog:bool = True):\n",
    "    if col != 'hnr':\n",
    "        if isLog:\n",
    "            rounded_col = np.round(\n",
    "                np.log10(data[col]), \n",
    "                precisionLog[col]\n",
    "            )\n",
    "        else:\n",
    "            rounded_col = np.round(\n",
    "                data[col],\n",
    "                precisionLinear[col]\n",
    "            )\n",
    "    else:\n",
    "        rounded_col = np.round(data[col], precisionLinear[col])\n",
    "    return rounded_col\n",
    "\n",
    "\n",
    "def perform_aggregation(partition_df, target, gender, descrete):\n",
    "    grouped_temp = partition_df.groupby(col).agg({\n",
    "        'frequency': 'first',\n",
    "    })\n",
    "\n",
    "    if not descrete:\n",
    "        grouped_temp['target'] = grouped_temp.index.map(\n",
    "            lambda val: target.loc[partition_df[partition_df[col] == val].index, :].mean().iloc[0]\n",
    "        )\n",
    "    else:\n",
    "        grouped_temp['target'] = GenderMapper[gender]\n",
    "\n",
    "    grouped_temp = grouped_temp.reset_index()\n",
    "\n",
    "    return grouped_temp\n",
    "    \n",
    "def plot_distribution(fig:plt.Figure, ax:plt.Axes, X_df:pd.DataFrame, col:str, target:pd.Series, isLog:bool=True, descrete:bool=False):    \n",
    "    temp = X_df[['gender', col]].copy()\n",
    "\n",
    "    temp[col] = round_column(temp, col, isLog=isLog)\n",
    "\n",
    "    male_df = temp[temp['gender'] == GenderMapper['male']].copy()\n",
    "    female_df = temp[temp['gender'] == GenderMapper['female']].copy()\n",
    "\n",
    "    male_df['frequency'] = male_df[col].map(male_df[col].value_counts())\n",
    "    female_df['frequency'] = female_df[col].map(female_df[col].value_counts())\n",
    "\n",
    "    male_grouped_df = perform_aggregation(male_df, target, 'male', descrete)\n",
    "    female_grouped_df = perform_aggregation(female_df, target, 'female', descrete)\n",
    "\n",
    "    female_grouped_df.index = female_grouped_df.index + male_grouped_df.index[-1]\n",
    "\n",
    "    combined_df = pd.concat([male_grouped_df, female_grouped_df]).reset_index()\n",
    "\n",
    "    cmap_, norm, mappable, handles = create_colors(combined_df.loc[:, 'target'], label='gender', use_continous=not descrete)\n",
    "\n",
    "    sc = ax.scatter(combined_df[col], \n",
    "                    combined_df['frequency'], \n",
    "                    c=cmap_(norm(combined_df['target'])), \n",
    "                    alpha=0.7)\n",
    "\n",
    "    if mappable:\n",
    "        fig.colorbar(mappable=mappable, ax=ax)\n",
    "    else:\n",
    "        ax.legend(handles=handles)\n",
    "\n",
    "for i in range(9):\n",
    "    col = list(precisionLog.keys())[i]\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    fig.suptitle(f'Distribution of {col.capitalize()} in log10 scale')\n",
    "\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    plot_distribution(fig, ax1, step3_dev_df, col, None, isLog=True, descrete=True)\n",
    "    ax1.set_xlabel(f'log_10({col.capitalize()})')\n",
    "    ax1.set_ylabel(f'Count')\n",
    "    \n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_title(\"Points colored with average age of grouped points\")\n",
    "\n",
    "    plot_distribution(fig, ax2, step3_dev_df, col, ages_df, isLog=True, descrete=False)\n",
    "    ax2.set_xlabel(f'log_10({col.capitalize()})')\n",
    "    ax1.set_ylabel(f'Count')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    fig.suptitle(f'Distribution of {col.capitalize()} in linear scale')\n",
    "\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    plot_distribution(fig, ax1, step3_dev_df, col, None, isLog=False, descrete=True)\n",
    "    ax1.set_xlabel(f'{col.capitalize()}')\n",
    "    ax2.set_ylabel(f'Count')\n",
    "    \n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_title(\"Points colored with average age of grouped points\")\n",
    "    plot_distribution(fig, ax2, step3_dev_df, col, ages_df, isLog=False, descrete=False)\n",
    "    ax2.set_ylabel(f'Count')\n",
    "    ax2.set_xlabel(f'{col.capitalize()}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "col = list(precisionLog.keys())[9]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.suptitle(f'Distribution of {col.capitalize()} in linear scale')\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "plot_distribution(fig, ax1, step3_dev_df, col, None, isLog=False, descrete=True)\n",
    "ax1.set_xlabel(f'{col.capitalize()}')\n",
    "ax1.set_ylabel(f'Count')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_title(\"Points colored with average age of grouped points\")\n",
    "plot_distribution(fig, ax2, step3_dev_df, col, ages_df, isLog=False, descrete=False)\n",
    "ax2.set_xlabel(f'{col.capitalize()}')\n",
    "ax2.set_ylabel(f'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_log_dev_df = step3_dev_df.copy()\n",
    "step3_log_eval_df = step3_eval_df.copy()\n",
    "\n",
    "for i, toSub in zip(precisionLog.keys(), [1, 0, 0, 1, 1, 1, 1, 1, 0, 0]):\n",
    "    if toSub == 1:\n",
    "        step3_log_dev_df.loc[:, i] = np.log10(step3_dev_df.loc[:, i])\n",
    "        step3_log_eval_df.loc[:, i] = np.log10(step3_eval_df.loc[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: only one scaler fitted on dev?\n",
    "\n",
    "step3_log_norm_dev_df = pd.DataFrame(StandardScaler().fit_transform(step3_log_dev_df), index=step3_log_dev_df.index, columns=step3_log_dev_df.columns)\n",
    "step3_log_norm_eval_df = pd.DataFrame(StandardScaler().fit_transform(step3_log_eval_df), index=step3_log_eval_df.index, columns=step3_log_eval_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp:pd.Series = step3_log_norm_dev_df.corr().loc['age', :].sort_values(ascending=False)\n",
    "display(temp.head(10))\n",
    "display(temp.tail(10))\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot()\n",
    "sns.heatmap(np.abs(step3_log_norm_dev_df.corr()), ax=ax)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_distripution(y_pred, y_val, precision):\n",
    "    errors = pd.DataFrame(np.round(y_pred.flatten() - y_val.values.flatten(), precision), columns=['error'])\n",
    "    error_counts = errors['error'].value_counts().reset_index()\n",
    "    error_counts.columns = ['error', 'count']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(error_counts['error'], error_counts['count'])\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Prediction Errors')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_df = step3_log_norm_dev_df.copy()\n",
    "X_train_val_df = X_train_val_df.drop(columns=['age'], axis=1)\n",
    "\n",
    "forest = RandomForestRegressor(random_state=341967)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val_df, ages_df, test_size=0.3, shuffle=True, random_state=341967)\n",
    "\n",
    "forest = forest.fit(X_train.values, y_train.values.reshape((-1,)))\n",
    "y_pred = forest.predict(X_val.values)\n",
    "\n",
    "display(root_mean_squared_error(y_val.values, y_pred))\n",
    "\n",
    "plot_error_distripution(y_pred, y_val, 0)\n",
    "#10.402057038409454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = forest.predict(X_train_val_df.values)\n",
    "\n",
    "display(np.max(y_eval_pred), np.min(y_eval_pred))\n",
    "display(np.max(ages_df), np.min(ages_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "abs(\n",
    "    cross_val_score(\n",
    "        RandomForestRegressor(n_jobs=-1, random_state=341967), X_train_val_df, ages_df, cv=10, scoring='neg_root_mean_squared_error', n_jobs=-1\n",
    "    ).mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "def grid(builder, configs, cv):\n",
    "    gs = GridSearchCV(builder(), configs, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=cv)\n",
    "    gs.fit(X_train.values, y_train.values.reshape((-1,)))\n",
    "    \n",
    "    return gs\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val_df, ages_df, test_size=0.3, shuffle=True, random_state=341967)\n",
    "\n",
    "forest = grid(RandomForestRegressor, {'n_estimators': [300, 500]}, 5)\n",
    "\n",
    "y_pred = forest.predict(X_val.values)\n",
    "\n",
    "display(root_mean_squared_error(y_val, y_pred))\n",
    "plot_error_distripution(y_pred, y_val, 0)\n",
    "\n",
    "#10.402057038409454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.csv\", \"w\") as fout:\n",
    "    fout.write(\"Id,Predicted\\n\")\n",
    "\n",
    "    for id, y in enumerate(y_eval_pred):\n",
    "        fout.write(f\"{id}, {y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "test_audios = np.random.choice(audio_dev, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_audios:\n",
    "    y, sr = librosa.load(AUDIOS_DEVELOPMENT + i, sr=sampling_rate)\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title(f\"Audio {i} as waveform\")\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.fft\n",
    "\n",
    "for i in test_audios:\n",
    "    y, sr = librosa.load(AUDIOS_DEVELOPMENT + i, sr=sampling_rate)\n",
    "\n",
    "    y_freq = np.abs(scipy.fft.fft(y))\n",
    "\n",
    "    f = np.linspace(0, sr, len(y_freq))\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title(f\"Spectrum of audio {i}\")\n",
    "    plt.semilogx(f[: len(f) // 2], y_freq[: len(f) // 2])\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_audios:\n",
    "    y, sr = librosa.load(AUDIOS_DEVELOPMENT + i, sr=sampling_rate)\n",
    "\n",
    "    x_stft = np.abs(librosa.stft(y))\n",
    "\n",
    "    x_stft = librosa.amplitude_to_db(x_stft, ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(f\"Spectrogram of audio {i}\")\n",
    "    librosa.display.specshow(x_stft, sr=sr, x_axis=\"time\", y_axis=\"log\")\n",
    "    plt.colorbar(format=\"%.1f dB\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel-spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_audios:\n",
    "    y, sr = librosa.load(AUDIOS_DEVELOPMENT + i, sr=sampling_rate)\n",
    "\n",
    "    x_mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "    x_mel = librosa.power_to_db(x_mel, ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(f\"Mel-spectrogram of audio {i}\")\n",
    "    librosa.display.specshow(x_mel, sr=sr, x_axis=\"time\", y_axis=\"mel\")\n",
    "    plt.colorbar(format=\"%.2f dB\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel-frequency cepstral coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_audios:\n",
    "    y, sr = librosa.load(AUDIOS_DEVELOPMENT + i, sr=sampling_rate)\n",
    "\n",
    "    # Extract 'n_mfcc' numbers of MFCCs components (here 20)\n",
    "    x_mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "\n",
    "    # Plot MFCCs\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title(f\"MFCC of audio {i}\")\n",
    "    librosa.display.specshow(x_mfccs, sr=sr, x_axis=\"time\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
