{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Estimation task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# Usual sklearn stuff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from CustomRegressor import TripleForestWithGenderDivision\n",
    "from combinationHyperParameters import CombinationHyperParameters\n",
    "\n",
    "# Distribution analysis\n",
    "import statistics\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Audio processing\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "\n",
    "import parselmouth as pm\n",
    "import maad as maad\n",
    "import maad.features\n",
    "import maad.sound\n",
    "\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "\n",
    "# Parallelism libraries\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pretty output and plots\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Not Needed\n",
    "# %matplotlib widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DEVELOPMENT = \"Dataset/development.csv\"\n",
    "FILE_EVALUATION = \"Dataset/evaluation.csv\"\n",
    "AUDIOS_DEVELOPMENT = \"Dataset/audios_development/\"\n",
    "AUDIOS_EVALUATION = \"Dataset/audios_evaluation/\"\n",
    "\n",
    "COMPUTE_ALL_AUDIO_FEATURES = False\n",
    "\n",
    "N_MFCC = 35\n",
    "FREQ_BIN = 32\n",
    "\n",
    "GenderMapper = {\n",
    "    'male': 1,\n",
    "    'female': -1\n",
    "}\n",
    "\n",
    "# How to round in the plotting function later on\n",
    "precisionLog = {\n",
    "    'mean_pitch':2, \n",
    "    'max_pitch':2, \n",
    "    'min_pitch':3, \n",
    "    'jitter':2, \n",
    "    'shimmer':2, \n",
    "    'energy':1, \n",
    "    'zcr_mean':2, \n",
    "    'spectral_centroid_mean':2,\n",
    "    'tempo':3,\n",
    "    'hnr':0\n",
    "}\n",
    "\n",
    "precisionLinear = {\n",
    "    'mean_pitch':-1, \n",
    "    'max_pitch':-2, \n",
    "    'min_pitch':0, \n",
    "    'jitter':3, \n",
    "    'shimmer':3, \n",
    "    'energy':3, \n",
    "    'zcr_mean':2, \n",
    "    'spectral_centroid_mean':-2,\n",
    "    'tempo':3,\n",
    "    'hnr':0\n",
    "}\n",
    "\n",
    "# let us try several models\n",
    "models =[\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(random_state=341967),\n",
    "    HistGradientBoostingRegressor(random_state=341967),\n",
    "    SVR(),\n",
    "    KNeighborsRegressor(),\n",
    "    MLPRegressor(random_state=341967),\n",
    "    Lasso(random_state=341967),\n",
    "    Ridge(random_state=341967),\n",
    "    DecisionTreeRegressor(random_state=341967),\n",
    "    TripleForestWithGenderDivision()\n",
    "]\n",
    "names=['Linear reg', 'Random Forest', 'HistGB', 'SVR', 'KNN', 'MLP', 'Lasso', 'Ridge', 'Decision Tree', 'Tfr']\n",
    "\n",
    "# Which audio feature to choose in the various files\n",
    "columns_correlator = {\n",
    "    k:v for k,v in zip(\n",
    "        [\n",
    "            \"time_domain.csv\", \n",
    "            \"freq_domain.csv\", \n",
    "            \"spectrogram.csv\", \n",
    "            \"mel_spectrogram.csv\", \n",
    "            \"mfcc.csv\", \n",
    "            \"hpss.csv\", \n",
    "            \"zcr.csv\", \n",
    "            \"poly.csv\", \n",
    "            \"formants.csv\",\n",
    "            \"temporal_median.csv\",\n",
    "            \"entropy.csv\"\n",
    "        ], \n",
    "        [\n",
    "            ['audio_length','mean_absolute_slope','pitch_iqr','voiced_frames','number_of_frames','sm','sv','ss','sk','Time 5%','Time 25%','Time 50%','Time 75%','Time 95%','duration_50','duration_90'], \n",
    "            ['dominant_frequency'], \n",
    "            ['spect_overall_mean'] + [f\"spect_frequency_mean_{t}\" for t in range(FREQ_BIN)],\n",
    "            ['mel_overall_mean'] + [f\"mel_frequency_mean_{t}\" for t in range(FREQ_BIN)],\n",
    "            [f\"mfcc_frequency_mean_{t}\" for t in range(N_MFCC)],\n",
    "            ['harmonic_overall_mean', 'harmonic_overall_var', 'percussion_overall_mean', 'percussion_overall_var'] + [f\"harmonic_frequency_mean_{t}\" for t in range(FREQ_BIN)] + [f\"harmonic_frequency_var_{t}\" for t in range(FREQ_BIN)] + [f\"percussion_frequency_mean_{t}\" for t in range(FREQ_BIN)] + [f\"percussion_frequency_var_{t}\" for t in range(FREQ_BIN)],\n",
    "            ['zcr'],\n",
    "            ['mean_coeffs', 'std_coeffs'],\n",
    "            ['f0_mean','f1_mean','f2_mean','f3_mean','f4_mean','f0_var','f1_var','f2_var','f3_var','f4_var'],\n",
    "            ['temporalMedian'],\n",
    "            ['temporal_entropy', 'frequence_entropy','mean_spectral_entropy']\n",
    "        ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_original_df = pd.read_csv(FILE_DEVELOPMENT, header=0, index_col=0)\n",
    "eval_original_df = pd.read_csv(FILE_EVALUATION, header=0, index_col=0)\n",
    "\n",
    "audio_dev = os.listdir(AUDIOS_DEVELOPMENT)\n",
    "audio_eval = os.listdir(AUDIOS_EVALUATION)\n",
    "\n",
    "print(audio_dev[:5])\n",
    "print(audio_eval[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order audios by integers and in increasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dev.sort(key=lambda x: int(x.split('.')[0]))\n",
    "audio_eval.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "print(audio_dev[:5])\n",
    "print(audio_eval[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of nan in development: {dev_original_df.isna().sum().sum()}\\n\")\n",
    "print(f\"Total number of nan in evaluation: {eval_original_df.isna().sum().sum()}\\n\")\n",
    "\n",
    "desc_dev_df = dev_original_df.describe()\n",
    "desc_eval_df = eval_original_df.describe()\n",
    "\n",
    "sampling_rate = dev_original_df['sampling_rate'].iloc[0]\n",
    "\n",
    "print(\"Standard deviation of sampling_rate:\")\n",
    "print(f\"In dev dataset: {float(desc_dev_df.loc['std', 'sampling_rate'])}\")\n",
    "print(f\"In eval dataset: {float(desc_eval_df.loc['std', 'sampling_rate'])}\")\n",
    "\n",
    "dev_df = dev_original_df.drop('sampling_rate', axis=1)\n",
    "eval_df = eval_original_df.drop('sampling_rate', axis=1)\n",
    "\n",
    "ages_df = dev_df[['age']]\n",
    "path_dev_df = dev_df[['path']]\n",
    "path_eval_df = eval_df[['path']]\n",
    "\n",
    "dev_df.drop(['path'], axis=1, inplace=True)\n",
    "eval_df.drop('path', axis=1, inplace=True)\n",
    "\n",
    "display(dev_df.head())\n",
    "display(eval_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enticity_df = dev_df['ethnicity'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "median_et = enticity_df.median()\n",
    "mean_et = enticity_df.mean()\n",
    "\n",
    "print(f\"Number of total distinct ethnicities: {enticity_df.shape[0]}\")\n",
    "print(f\"Number of ethnicities with only one appearance: {enticity_df[enticity_df == 1].shape[0]}\")\n",
    "print(f\"Median value: {median_et}\")\n",
    "print(f\"Mean value: {mean_et}\")\n",
    "\n",
    "display(enticity_df)\n",
    "\n",
    "# enticity_df[enticity_df > mean_et].plot()\n",
    "\n",
    "etnie_chosen = sorted(list(set(enticity_df[enticity_df > median_et].index))) + ['others']\n",
    "\n",
    "print(f\"Number of ethnicities kept: {etnie_chosen.__len__()}\")\n",
    "\n",
    "display('Ethnicities in eval dataset kept after analysis:')\n",
    "display(eval_df.loc[eval_df['ethnicity'].isin(etnie_chosen), 'ethnicity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ethnicity(X_df:pd.DataFrame):\n",
    "    aggregated_ethnicity_df = X_df.copy()\n",
    "\n",
    "    try:\n",
    "        aggregated_ethnicity_df.drop(columns=['ethnicity'], axis=1, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    return aggregated_ethnicity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dev_original_df['gender'].value_counts())\n",
    "display(eval_original_df['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gender(X_df:pd.DataFrame, mapper):\n",
    "    encoded_df = X_df.copy()\n",
    "    for gender, value in mapper.items():\n",
    "        encoded_df.loc[encoded_df['gender'] == gender, 'gender'] = value\n",
    "\n",
    "    encoded_df.loc[encoded_df['gender'] == 'famale', 'gender'] = GenderMapper['female']\n",
    "\n",
    "    encoded_df['gender'] = encoded_df['gender'].astype(float)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Number of values in column 'tempo' that do not start with '[':\n",
    "    1.In dev: {dev_df[dev_df['tempo'].map(lambda x: x[0]) == '['].shape[0] - dev_df.shape[0]}\n",
    "    2.In eval: {dev_df[dev_df['tempo'].map(lambda x: x[0]) == '['].shape[0] - dev_df.shape[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tempo(X_df):\n",
    "    encoded_df = X_df.copy()\n",
    "\n",
    "    encoded_df['tempo'] = encoded_df['tempo'].map(lambda x: float(x.strip('[').strip(']')))\n",
    "    \n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_dev_df = encode_ethnicity(dev_df)\n",
    "step1_eval_df = encode_ethnicity(eval_df)\n",
    "\n",
    "step2_dev_df = encode_gender(step1_dev_df, GenderMapper)\n",
    "step2_eval_df = encode_gender(step1_eval_df, GenderMapper)\n",
    "\n",
    "step3_dev_df = encode_tempo(step2_dev_df)\n",
    "step3_eval_df = encode_tempo(step2_eval_df)\n",
    "\n",
    "display(step3_dev_df.head(5))\n",
    "display(step3_eval_df.head(5))\n",
    "\n",
    "display(step3_dev_df.describe())\n",
    "display(step3_eval_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior analysis and $log_{10}$ scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colors(values:pd.Series, label:str, use_continous:bool=False, \n",
    "                  cmap_continuous = cm.viridis, cmap_discrete = cm.rainbow):\n",
    "    if use_continous:\n",
    "        cmap_ = cmap_continuous\n",
    "        # Alternative normalization without iterquartile ranges:\n",
    "        norm = plt.Normalize(vmin=np.min(values), vmax=np.max(values)) \n",
    "        \n",
    "        mappable = cm.ScalarMappable(norm=norm, cmap=cmap_)\n",
    "        handles = None\n",
    "    else:\n",
    "        cmap_ = cmap_discrete\n",
    "        norm = plt.Normalize(vmin=np.min(values), vmax=np.max(values)) \n",
    "        \n",
    "        mappable = None\n",
    "        handles = [\n",
    "            Line2D(\n",
    "                [0], [0], marker='o', color='none', linestyle='None', \n",
    "                markeredgewidth=0, markerfacecolor=cmap_(norm(val)), \n",
    "                markersize=10, label=label\n",
    "            ) for label, val in GenderMapper.items()\n",
    "        ]\n",
    "\n",
    "    return cmap_, norm, mappable, handles \n",
    "\n",
    "def round_column(data: pd.DataFrame, col: str, isLog:bool = True):\n",
    "    if col != 'hnr':\n",
    "        if isLog:\n",
    "            rounded_col = np.round(\n",
    "                np.log10(data[col]), \n",
    "                precisionLog[col]\n",
    "            )\n",
    "        else:\n",
    "            rounded_col = np.round(\n",
    "                data[col],\n",
    "                precisionLinear[col]\n",
    "            )\n",
    "    else:\n",
    "        rounded_col = np.round(data[col], precisionLinear[col])\n",
    "    return rounded_col\n",
    "\n",
    "\n",
    "def perform_aggregation(partition_df, col, target, gender, descrete):\n",
    "    grouped_temp = partition_df.groupby(col).agg({\n",
    "        'frequency': 'first',\n",
    "    })\n",
    "\n",
    "    if not descrete:\n",
    "        grouped_temp['target'] = grouped_temp.index.map(\n",
    "            lambda val: target.loc[partition_df[partition_df[col] == val].index, :].mean().iloc[0]\n",
    "        )\n",
    "    else:\n",
    "        grouped_temp['target'] = GenderMapper[gender]\n",
    "\n",
    "    grouped_temp = grouped_temp.reset_index()\n",
    "\n",
    "    return grouped_temp\n",
    "    \n",
    "def plot_distribution(fig:plt.Figure, ax:plt.Axes, X_df:pd.DataFrame, col:str, target:pd.Series, isLog:bool=True, descrete:bool=False):    \n",
    "    temp = X_df[['gender', col]].copy()\n",
    "\n",
    "    temp[col] = round_column(temp, col, isLog=isLog)\n",
    "\n",
    "    male_df = temp[temp['gender'] == GenderMapper['male']].copy()\n",
    "    female_df = temp[temp['gender'] == GenderMapper['female']].copy()\n",
    "\n",
    "    male_df['frequency'] = male_df[col].map(male_df[col].value_counts())\n",
    "    female_df['frequency'] = female_df[col].map(female_df[col].value_counts())\n",
    "\n",
    "    male_grouped_df = perform_aggregation(male_df, col, target, 'male', descrete)\n",
    "    female_grouped_df = perform_aggregation(female_df, col, target, 'female', descrete)\n",
    "\n",
    "    female_grouped_df.index = female_grouped_df.index + male_grouped_df.index[-1]\n",
    "\n",
    "    combined_df = pd.concat([male_grouped_df, female_grouped_df]).reset_index()\n",
    "\n",
    "    cmap_, norm, mappable, handles = create_colors(combined_df.loc[:, 'target'], label='gender', use_continous=not descrete)\n",
    "\n",
    "    ax.scatter(\n",
    "        combined_df[col], \n",
    "        combined_df['frequency'], \n",
    "        c=cmap_(norm(combined_df['target'])), \n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    if mappable:\n",
    "        fig.colorbar(mappable=mappable, ax=ax)\n",
    "    else:\n",
    "        ax.legend(handles=handles)\n",
    "\n",
    "def tabular_data_distribution():\n",
    "    for i in range(9):\n",
    "        col = list(precisionLog.keys())[i]\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        fig.suptitle(f'Distribution of {col.capitalize()} in linear scale')\n",
    "\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        plot_distribution(fig, ax1, step3_dev_df, col, None, isLog=False, descrete=True)\n",
    "        ax1.set_xlabel(f'{col.capitalize()}')\n",
    "        ax1.set_ylabel(f'Count')\n",
    "        \n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.set_title(\"Points colored with average age of grouped points\")\n",
    "        plot_distribution(fig, ax2, step3_dev_df, col, ages_df, isLog=False, descrete=False)\n",
    "        ax2.set_ylabel(f'Count')\n",
    "        ax2.set_xlabel(f'{col.capitalize()}')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        fig.suptitle(f'Distribution of {col.capitalize()} in log10 scale')\n",
    "\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        plot_distribution(fig, ax1, step3_dev_df, col, ages_df, isLog=True, descrete=True)\n",
    "        ax1.set_xlabel(f'log_10({col.capitalize()})')\n",
    "        ax1.set_ylabel(f'Count')\n",
    "        \n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.set_title(\"Points colored with average age of grouped points\")\n",
    "\n",
    "        plot_distribution(fig, ax2, step3_dev_df, col, ages_df, isLog=True, descrete=False)\n",
    "        ax2.set_xlabel(f'log_10({col.capitalize()})')\n",
    "        ax1.set_ylabel(f'Count')\n",
    "        plt.show()\n",
    "\n",
    "    col = list(precisionLog.keys())[9]\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    fig.suptitle(f'Distribution of {col.capitalize()} in linear scale')\n",
    "\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    plot_distribution(fig, ax1, step3_dev_df, col, None, isLog=False, descrete=True)\n",
    "    ax1.set_xlabel(f'{col.capitalize()}')\n",
    "    ax1.set_ylabel(f'Count')\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_title(\"Points colored with average age of grouped points\")\n",
    "    plot_distribution(fig, ax2, step3_dev_df, col, ages_df, isLog=False, descrete=False)\n",
    "    ax2.set_xlabel(f'{col.capitalize()}')\n",
    "    ax2.set_ylabel(f'Count')\n",
    "    plt.show()\n",
    "\n",
    "tabular_data_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_log_dev_df = step3_dev_df.copy()\n",
    "step3_log_eval_df = step3_eval_df.copy()\n",
    "\n",
    "for i, toSub in zip(precisionLog.keys(), [1, 0, 0, 1, 1, 1, 1, 1, 0, 0]):\n",
    "    if toSub == 1:\n",
    "        step3_log_dev_df.loc[:, i] = np.log10(step3_dev_df.loc[:, i])\n",
    "        step3_log_eval_df.loc[:, i] = np.log10(step3_eval_df.loc[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp:pd.Series = step3_log_dev_df.corr().loc['age', :].sort_values(ascending=False)\n",
    "display(temp)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot()\n",
    "sns.heatmap(np.abs(step3_log_dev_df.corr()), ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_age_dev_df = step3_log_dev_df.drop(columns=['age'], axis=1)\n",
    "\n",
    "scaler = StandardScaler().fit(no_age_dev_df)\n",
    "\n",
    "step3_log_norm_dev_df = pd.DataFrame(scaler.transform(no_age_dev_df), columns=no_age_dev_df.columns)\n",
    "step3_log_norm_eval_df = pd.DataFrame(scaler.transform(step3_log_eval_df), columns=step3_log_eval_df.columns)\n",
    "\n",
    "display(step3_log_norm_dev_df.head())\n",
    "display(step3_log_norm_eval_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_distripution(y_pred, y_val, precision):\n",
    "    errors = pd.DataFrame(np.round(y_pred.flatten() - y_val.values.flatten(), precision), columns=['error'])\n",
    "    error_counts = errors['error'].value_counts().reset_index()\n",
    "    error_counts.columns = ['error', 'count']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(error_counts['error'], error_counts['count'])\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Prediction Errors')\n",
    "    plt.show()\n",
    "    return error_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross_val_score(make_pipeline(StandardScaler(), RandomForestRegressor()), step3_log_dev_df, ages_df, cv=15, scoring='neq_mean_squared_error').mean().abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_df = step3_log_norm_dev_df.copy()\n",
    "\n",
    "first_forest = RandomForestRegressor(random_state=341967)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "first_forest.fit(X_train, y_train)\n",
    "y_pred = first_forest.predict(X_val)\n",
    "\n",
    "display(root_mean_squared_error(y_val, y_pred))\n",
    "\n",
    "_ = plot_error_distripution(y_pred, y_val, 0)\n",
    "#10.455056281368881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look at feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = [(a, float(b)) for a,b in sorted(zip(first_forest.feature_names_in_, first_forest.feature_importances_), key=lambda x:x[1] , reverse=True)]\n",
    "display(imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = PrettyTable(['Model', 'RMSE'])\n",
    "X_train_val_df = step3_log_norm_dev_df.copy()\n",
    "\n",
    "for model,name in zip(models, names):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    t.add_row([name, root_mean_squared_error(y_val, y_pred)])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = first_forest.predict(step3_log_norm_dev_df.values)\n",
    "\n",
    "print(f\"\"\"Max and min value of prediction:\n",
    "    {float(np.max(y_dev_pred))}, {float(np.min(y_dev_pred))}\"\"\")\n",
    "\n",
    "print(f\"\"\"Max and min value of ground truth::\n",
    "    {float(np.max(ages_df))}, {float(np.min(ages_df))}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.csv\", \"w\") as fout:\n",
    "    fout.write(\"Id,Predicted\\n\")\n",
    " \n",
    "    for id, y in enumerate(first_forest.predict(step3_log_norm_eval_df)):\n",
    "        fout.write(f\"{id},{y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'random_state': [341967]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    RandomForestRegressor(), \n",
    "    param_grid, \n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    n_jobs=9, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs.fit(step3_log_norm_dev_df, ages_df)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", gs.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", gs.best_score_)\n",
    "\n",
    "best_rf = gs.best_estimator_\n",
    "\n",
    "_ = plot_error_distripution(best_rf.predict(step3_log_norm_dev_df), ages_df, 0)\n",
    "\n",
    "#10.424189101247185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = best_rf.predict(step3_log_norm_dev_df.values)\n",
    "\n",
    "print(f\"\"\"Max and min value of prediction:\n",
    "    {float(np.max(y_dev_pred))}, {float(np.min(y_dev_pred))}\"\"\")\n",
    "\n",
    "print(f\"\"\"Max and min value of ground truth::\n",
    "    {float(np.max(ages_df))}, {float(np.min(ages_df))}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr = TripleForestWithGenderDivision(        \n",
    "    {'n_estimators': 100,  'random_state': 341967}, \n",
    "    {'n_estimators': 100, 'random_state': 341967}, \n",
    "    {'n_estimators': 100,  'random_state': 341967}\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(step3_log_norm_dev_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "tfr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tfr.predict(X_val)\n",
    "\n",
    "display(root_mean_squared_error(y_val, y_pred))\n",
    "\n",
    "_ = plot_error_distripution(y_pred.values, y_val, 0)\n",
    "\n",
    "y_eval_pred = tfr.predict(step3_log_norm_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.csv\", \"w\") as fout:\n",
    "    fout.write(\"Id,Predicted\\n\")\n",
    " \n",
    "    for id, y in enumerate(y_eval_pred):\n",
    "        fout.write(f\"{id},{y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio(y:np.ndarray, sr:float, time=False, freq=False, spectrogram=False, mel=False, mfcc=False, hp=False, poly=False,plot=True):\n",
    "    \"\"\"\n",
    "        Returns the thing plotted\\n\n",
    "        If freq = True, returns the frequencies used too\\n\n",
    "        If hp=True, returns Harmonic and Percussion\\n\n",
    "        If all False, returns y\n",
    "    \"\"\"\n",
    "    n_fft = (FREQ_BIN - 1) * 2\n",
    "\n",
    "    if time:\n",
    "        if plot:\n",
    "            plt.figure(figsize=(12, 3))\n",
    "            plt.title(f\"Audio as waveform\")\n",
    "            librosa.display.waveshow(y, sr=sr)\n",
    "\n",
    "        return y\n",
    "    if freq:\n",
    "        y_freq = np.abs(scipy.fft.fft(y))\n",
    "        f = np.linspace(0, sr, len(y_freq))\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(12, 3))\n",
    "            plt.title(f\"Spectrum of audio\")\n",
    "            plt.semilogx(f[: len(f) // 2], y_freq[: len(f) // 2])\n",
    "            plt.xlabel(\"Frequency (Hz)\")\n",
    "\n",
    "        return y_freq, f\n",
    "    if spectrogram:    \n",
    "        y_stft = np.abs(librosa.stft(y, n_fft=n_fft))\n",
    "        y_stft_db = librosa.amplitude_to_db(y_stft, ref=np.max)\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.title(f\"Spectrogram of audio\")\n",
    "            librosa.display.specshow(y_stft_db, sr=sr, x_axis=\"time\", y_axis=\"log\")\n",
    "            plt.colorbar(format=\"%.1f dB\")\n",
    "\n",
    "        return y_stft, y_stft_db\n",
    "    if mel:\n",
    "        y_mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=FREQ_BIN)\n",
    "        y_mel_db = librosa.power_to_db(y_mel, ref=np.max)\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.title(f\"Mel-spectrogram of audio\")\n",
    "            librosa.display.specshow(y_mel_db, sr=sr, x_axis=\"time\", y_axis=\"mel\")\n",
    "            plt.colorbar(format=\"%.2f dB\")\n",
    "        \n",
    "        return y_mel, y_mel_db\n",
    "    if mfcc:\n",
    "        y_mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC)\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.title(f\"MFCC of audio\")\n",
    "            librosa.display.specshow(y_mfccs, sr=sr, x_axis=\"time\")\n",
    "            plt.colorbar()\n",
    "\n",
    "        return y_mfccs\n",
    "    if hp:\n",
    "        y_stft = librosa.stft(y, n_fft=n_fft)\n",
    "        H, P = librosa.decompose.hpss(y_stft)\n",
    "        Hmag = np.abs(H)\n",
    "        Pmag = np.abs(P)\n",
    "\n",
    "        if plot:\n",
    "            Hdb = librosa.amplitude_to_db(Hmag, ref=np.max)\n",
    "            Pdb = librosa.amplitude_to_db(Pmag, ref=np.max)\n",
    "            \n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.title(f\"Harmonic source of audio\")\n",
    "            librosa.display.specshow(Hdb, sr=sr, x_axis=\"time\", y_axis=\"log\")\n",
    "            plt.colorbar(format=\"%.2f dB\")\n",
    "\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.title(f\"Percussive source of audio\")\n",
    "            librosa.display.specshow(Pdb, sr=sr, x_axis=\"time\", y_axis=\"log\")\n",
    "            plt.colorbar(format=\"%.2f dB\")\n",
    "\n",
    "        return librosa.istft(H), Hmag, librosa.istft(P), Pmag\n",
    "    if poly:\n",
    "        y_poly = librosa.feature.poly_features(y=y, sr=sr)\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.title(f\"Polynomial feature of audio\")\n",
    "            plt.plot(y_poly[0], label=\"Coeffs order 0\")\n",
    "            plt.plot(y_poly[1], label=\"Coeffs order 1\")\n",
    "            plt.legend()\n",
    "\n",
    "        return y_poly\n",
    "    plt.show()\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        0.0, \n",
    "        index=[audio_id], \n",
    "        columns=[\n",
    "            'audio_length'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sr = sampling_rate\n",
    "    pitch = parselmouth.Sound(dir+audio).to_pitch()\n",
    "\n",
    "    y = pitch.selected_array\n",
    "    y = y[~(y['frequency'] == 0)]\n",
    "\n",
    "    median_pitch = np.nanmedian(y['frequency'])\n",
    "    median_pitch_i = np.argmin(abs(y['frequency'] - median_pitch))\n",
    "    \n",
    "    median_pitch_strength = y['strength'][median_pitch_i]\n",
    "    pitch_iqr = scipy.stats.iqr(y['frequency'])\n",
    "\n",
    "    mean_absolute_slope = pitch.get_mean_absolute_slope()\n",
    "    voiced_frames = pitch.count_voiced_frames()\n",
    "    number_of_frames = pitch.get_number_of_frames()\n",
    "\n",
    "    min_pitch = np.min(y['frequency'])\n",
    "    max_pitch = np.max(y['frequency'])\n",
    "\n",
    "    series = maad.features.all_temporal_features(librosa.load(dir+audio, sr = sr)[0], fs=sr, nperseg=256)\n",
    "    series.index = [audio_id]\n",
    "\n",
    "    res['audio_length'] = pitch.duration\n",
    "    res['mean_absolute_slope'] = mean_absolute_slope\n",
    "    res['median_pitch_pm'] = median_pitch\n",
    "    res['median_pitch_strength'] = median_pitch_strength\n",
    "    res['pitch_iqr'] = pitch_iqr\n",
    "    res['min_pitch_pm'] = min_pitch\n",
    "    res['max_pitch_pm'] = max_pitch\n",
    "    res['voiced_frames'] = voiced_frames\n",
    "    res['number_of_frames'] = number_of_frames\n",
    "\n",
    "    res[series.columns] = series.values\n",
    "\n",
    "    if plot:\n",
    "        plot_audio(y, sr, time=True, plot=plot)\n",
    "\n",
    "        print(f\"Audio: {audio}\")\n",
    "        print(f\"Length: {pitch.duration}\")\n",
    "    return res\n",
    "\n",
    "time_domain(AUDIOS_DEVELOPMENT, audio_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_domain(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "    \n",
    "    res = pd.DataFrame(0.0, index=[audio_id], columns=['dominant_frequency'])\n",
    "\n",
    "    y, sr = librosa.load(dir + audio, sr=sampling_rate)\n",
    "\n",
    "    y_freq, f = plot_audio(y, sr, freq=True, plot=plot)\n",
    "\n",
    "    y_mag = np.abs(y_freq)\n",
    "    dominant_frequency = f[np.argmax(y_mag)]\n",
    "\n",
    "    threshold = np.max(y_mag) * 0.1\n",
    "    significant_freqs = f[y_mag > threshold]\n",
    "\n",
    "    if len(significant_freqs) > 0:\n",
    "        lowest_freq_in_spectrum, highest_freq_in_spectrum = significant_freqs[0], significant_freqs[-1]\n",
    "    else:\n",
    "        lowest_freq_in_spectrum, highest_freq_in_spectrum = 0, 0\n",
    "\n",
    "    spectrum_wide = highest_freq_in_spectrum - lowest_freq_in_spectrum\n",
    "\n",
    "    res['dominant_frequency'] = dominant_frequency\n",
    "    res['lowest_freq_in_spectrum'] = lowest_freq_in_spectrum\n",
    "    res['highest_freq_in_spectrum'] = highest_freq_in_spectrum\n",
    "    res['spectrum_wide'] = spectrum_wide\n",
    "\n",
    "    if plot:\n",
    "        print(f\"Audio: {audio}\")\n",
    "        print(f\"Dominant frequency: {dominant_frequency}\")\n",
    "\n",
    "        print(f\"Lowest important freq:{lowest_freq_in_spectrum}\")\n",
    "        print(f\"Highest important freq:{highest_freq_in_spectrum}\")\n",
    "        print(f\"Length of spectrum: {highest_freq_in_spectrum - lowest_freq_in_spectrum}\\n\")\n",
    "\n",
    "    return res\n",
    "\n",
    "freq_domain(AUDIOS_DEVELOPMENT, audio_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "\n",
    "    spect_frequency_mean_cols = [f\"spect_frequency_mean_{t}\" for t in range(FREQ_BIN)]\n",
    "    spect_frequency_var_cols  = [f\"spect_frequency_var_{t}\" for t in range(FREQ_BIN)]\n",
    "\n",
    "    res = pd.DataFrame(0.0, index=[audio_id], columns=['spect_overall_mean'])\n",
    "\n",
    "    y, sr = librosa.load(dir + audio, sr=sampling_rate)\n",
    "\n",
    "    S, _ = plot_audio(y, sr, spectrogram=True, plot=plot)\n",
    "\n",
    "    spect_frequency_mean = S.mean(axis=1)\n",
    "    spect_frequency_variance = S.var(axis=1)\n",
    "    # spect_frequency_skewness = skew(S, axis=1)\n",
    "    # spect_frequency_kurtosis = kurtosis(S, axis=1)\n",
    "\n",
    "    spect_overall_mean = S.mean()\n",
    "    spect_overall_var = S.var()\n",
    "\n",
    "    frequencies = librosa.fft_frequencies(sr=sr)\n",
    "\n",
    "    # Find the indices corresponding to 250 Hz and 650 Hz\n",
    "    low_idx = np.argmax(frequencies >= 250)\n",
    "    high_idx = np.argmax(frequencies >= 650)\n",
    "    energy = np.sum(np.abs(S)[low_idx:high_idx, :]**2)\n",
    "\n",
    "    res['spect_overall_mean'] = spect_overall_mean\n",
    "    res['spect_overall_var'] = spect_overall_var\n",
    "\n",
    "    res[spect_frequency_mean_cols] = spect_frequency_mean\n",
    "    res[spect_frequency_var_cols] = spect_frequency_variance\n",
    "\n",
    "    res['spectralEnergy250-650'] = energy\n",
    "    \n",
    "    if plot:\n",
    "        print(f\"Audio: {audio}\")\n",
    "\n",
    "        print(f\"Overall mean:\\n{S.mean()}\")\n",
    "        print(f\"Overall variance:\\n{S.var()}\")\n",
    "        \n",
    "        print(f\"Frequency mean:\\n{spect_frequency_mean}\")\n",
    "        print(f\"Frequency variance:\\n{spect_frequency_variance}\")\n",
    "        # print(f\"Frequency skewness:\\n{spect_frequency_skewness}\")\n",
    "        # print(f\"Frequency kurtosis:\\n{spect_frequency_kurtosis}\")\n",
    "\n",
    "    return res\n",
    "\n",
    "spectrogram(AUDIOS_DEVELOPMENT, audio_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel-spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spectrogram(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "\n",
    "    mel_frequency_mean_cols = [f\"mel_frequency_mean_{t}\" for t in range(FREQ_BIN)]\n",
    "    mel_frequency_var_cols  = [f\"mel_frequency_var_{t}\" for t in range(FREQ_BIN)]\n",
    "\n",
    "    res = pd.DataFrame(0.0, index=[audio_id], columns=['mel_overall_mean'])\n",
    "    y, sr = librosa.load(dir + audio, sr=sampling_rate)\n",
    "\n",
    "    S, _ = plot_audio(y, sr, mel=True, plot=plot)\n",
    "\n",
    "    mel_frequency_mean =     S.mean(axis=1)\n",
    "    mel_frequency_variance = S.var(axis=1)\n",
    "    # mel_frequency_skewness = skew(S, axis=1)\n",
    "    # mel_frequency_kurtosis = kurtosis(S, axis=1)\n",
    "\n",
    "    overall_mean = S.mean()\n",
    "    overall_var = S.var()\n",
    "\n",
    "    res['mel_overall_mean'] = overall_mean\n",
    "    res['mel_overall_var'] = overall_var\n",
    "\n",
    "    res[mel_frequency_mean_cols] = mel_frequency_mean\n",
    "    res[mel_frequency_var_cols] = mel_frequency_variance\n",
    "\n",
    "    if plot:\n",
    "        print(f\"Audio: {audio}\")\n",
    "        \n",
    "        print(f\"Overall mean:\\n{overall_mean}\")\n",
    "        print(f\"Overall variance:\\n{overall_var}\")\n",
    "        \n",
    "        print(f\"Frequency mean:\\n{mel_frequency_mean}\")\n",
    "        print(f\"Frequency variance:\\n{mel_frequency_variance}\")\n",
    "        display('')\n",
    "\n",
    "    return res\n",
    "\n",
    "mel_spectrogram(AUDIOS_DEVELOPMENT, audio_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel-frequency cepstral coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "\n",
    "    mfcc_frequency_mean_cols = [f\"mfcc_frequency_mean_{t}\" for t in range(N_MFCC)]\n",
    "\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "    res = pd.DataFrame(0, index=[audio_id], columns=mfcc_frequency_mean_cols, dtype=float)\n",
    "\n",
    "    sr = sampling_rate\n",
    "    \n",
    "    y, sr = librosa.load(dir+audio, sr=sr)\n",
    "\n",
    "    S = plot_audio(y, sr, mfcc=True, plot=plot)\n",
    "\n",
    "    mfcc_frequency_mean = S.mean(axis=1)\n",
    "\n",
    "    serie = pd.Series(mfcc_frequency_mean, index=mfcc_frequency_mean_cols)\n",
    "    \n",
    "    res[mfcc_frequency_mean_cols] = serie\n",
    "    \n",
    "    if plot:\n",
    "        print(f\"Audio: {audio}\")\n",
    "        \n",
    "        print(f\"Frequency mean:    \\n{mfcc_frequency_mean}\")\n",
    "        \n",
    "    return res\n",
    "mfcc(AUDIOS_DEVELOPMENT, audio_dev[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harmonic-percussive source separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpss(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "\n",
    "    harmonic_frequency_mean_cols = [f\"harmonic_frequency_mean_{t}\" for t in range(FREQ_BIN)]\n",
    "    harmonic_frequency_var_cols = [f\"harmonic_frequency_var_{t}\" for t in range(FREQ_BIN)]\n",
    "\n",
    "    percussion_frequency_mean_cols = [f\"percussion_frequency_mean_{t}\" for t in range(FREQ_BIN)]\n",
    "    percussion_frequency_var_cols = [f\"percussion_frequency_var_{t}\" for t in range(FREQ_BIN)]\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        0.0, \n",
    "        index=[audio_id], \n",
    "        columns=\n",
    "            ['harmonic_overall_mean', 'harmonic_overall_var', 'percussion_overall_mean', 'percussion_overall_var']+\n",
    "            harmonic_frequency_mean_cols+\n",
    "            harmonic_frequency_var_cols+\n",
    "            percussion_frequency_mean_cols+\n",
    "            percussion_frequency_var_cols\n",
    "    )\n",
    "\n",
    "    y, sr = librosa.load(dir + audio, sr=sampling_rate)\n",
    "\n",
    "    h, Hmag, p, Pmag = plot_audio(y, sr, hp=True, plot=plot)\n",
    "    \n",
    "    harmonic_frequency_mean     = Hmag.mean(axis=1)\n",
    "    harmonic_frequency_variance = Hmag.var(axis=1)\n",
    "\n",
    "    percussion_frequency_mean =     Pmag.mean(axis=1)\n",
    "    percussion_frequency_variance = Pmag.var(axis=1)\n",
    "\n",
    "    harmonic_overall_mean = Hmag.mean()\n",
    "    harmonic_overall_var = Hmag.var()\n",
    "\n",
    "    percussion_overall_mean = Pmag.mean()\n",
    "    percussion_overall_var = Pmag.var()\n",
    "\n",
    "    res['harmonic_overall_mean'] = harmonic_overall_mean\n",
    "    res['harmonic_overall_var'] = harmonic_overall_var        \n",
    "    res['percussion_overall_mean'] = percussion_overall_mean\n",
    "    res['percussion_overall_var'] = percussion_overall_var\n",
    "\n",
    "    res[harmonic_frequency_mean_cols] = harmonic_frequency_mean\n",
    "    res[harmonic_frequency_var_cols] = harmonic_frequency_variance\n",
    "    res[percussion_frequency_mean_cols] = percussion_frequency_mean\n",
    "    res[percussion_frequency_var_cols] = percussion_frequency_variance\n",
    "\n",
    "    if plot:\n",
    "        print(f\"Overall mean for harmonic source:\\n{harmonic_overall_mean}\")\n",
    "        print(f\"Overall variance for harmonic source:\\n{harmonic_overall_var}\")\n",
    "        print(f\"Overall mean for percussion source:\\n{percussion_overall_mean}\")\n",
    "        print(f\"Overall variance for percussion source:\\n{percussion_overall_var}\")\n",
    "\n",
    "        display(\"\")\n",
    "        \n",
    "        plot_audio(h, sr, mfcc=True, plot=plot)\n",
    "        plot_audio(p, sr, mfcc=True, plot=plot)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-crossing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "\n",
    "    res = pd.DataFrame(0.0, index=[audio_id], columns=['zcr'])\n",
    "    \n",
    "    y, sr = librosa.load(dir + audio, sr=sampling_rate)\n",
    "\n",
    "    zero_astfly = librosa.zero_crossings(y, pad=False).sum()\n",
    "    zcr_ = float(zero_astfly/(y.shape[0]/sr))\n",
    "\n",
    "    res['zcr'] = zcr_\n",
    "\n",
    "    if plot:\n",
    "        display(zcr_)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PolyFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(dir, audio, plot=False):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "\n",
    "    res = pd.DataFrame(0.0, index=[audio_id], columns=['mean_coeffs', 'std_coeffs'])\n",
    "    \n",
    "    y, sr = librosa.load(dir + audio, sr=sampling_rate)\n",
    "\n",
    "    y_poly = plot_audio(y, sr, poly=True, plot=plot)\n",
    "\n",
    "    res['mean_coeffs'] = y_poly[1].mean()\n",
    "    res['std_coeffs'] = y_poly[1].std()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fundamental Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measureFormants(dir, audio, f0min=75,f0max=600):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "    \n",
    "    res = pd.DataFrame(\n",
    "        0.0, \n",
    "        index=[audio_id], \n",
    "        columns=[\n",
    "            'f0_mean', 'f1_mean', 'f2_mean', 'f3_mean', 'f4_mean', \n",
    "            'f1_median', 'f2_median', 'f3_median', 'f4_median', \n",
    "            'f0_var', 'f1_var', 'f2_var', 'f3_var', 'f4_var'\n",
    "        ]\n",
    "    )\n",
    "    sound = parselmouth.Sound(dir+audio)\n",
    "    pitch = call(sound, \"To Pitch (cc)\", 0, f0min, 15, 'no', 0.03, 0.45, 0.01, 0.35, 0.14, f0max)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    \n",
    "    formants = call(sound, \"To Formant (burg)\", 0.0025, 5, 5000, 0.025, 50)\n",
    "    numPoints = call(pointProcess, \"Get number of points\")\n",
    "\n",
    "    f0_mean = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    f0_var = call(pitch, \"Get standard deviation\", 0 ,0, \"Hertz\")**2\n",
    "\n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    f3_list = []\n",
    "    f4_list = []\n",
    "    \n",
    "    # Measure formants only at glottal pulses\n",
    "    for point in range(0, numPoints):\n",
    "        point += 1\n",
    "        t = call(pointProcess, \"Get time from index\", point)\n",
    "        f1 = call(formants, \"Get value at time\", 1, t, 'Hertz', 'Linear')\n",
    "        f2 = call(formants, \"Get value at time\", 2, t, 'Hertz', 'Linear')\n",
    "        f3 = call(formants, \"Get value at time\", 3, t, 'Hertz', 'Linear')\n",
    "        f4 = call(formants, \"Get value at time\", 4, t, 'Hertz', 'Linear')\n",
    "        f1_list.append(f1)\n",
    "        f2_list.append(f2)\n",
    "        f3_list.append(f3)\n",
    "        f4_list.append(f4)\n",
    "    \n",
    "    f1_list = [f1 for f1 in f1_list if str(f1) != 'nan']\n",
    "    f2_list = [f2 for f2 in f2_list if str(f2) != 'nan']\n",
    "    f3_list = [f3 for f3 in f3_list if str(f3) != 'nan']\n",
    "    f4_list = [f4 for f4 in f4_list if str(f4) != 'nan']\n",
    "    \n",
    "    f1_mean = statistics.mean(f1_list)\n",
    "    f2_mean = statistics.mean(f2_list)\n",
    "    f3_mean = statistics.mean(f3_list)\n",
    "    f4_mean = statistics.mean(f4_list)\n",
    "    \n",
    "    f1_median = statistics.median(f1_list)\n",
    "    f2_median = statistics.median(f2_list)\n",
    "    f3_median = statistics.median(f3_list)\n",
    "    f4_median = statistics.median(f4_list)\n",
    "\n",
    "    f1_var = statistics.variance(f1_list)\n",
    "    f2_var = statistics.variance(f2_list)\n",
    "    f3_var = statistics.variance(f3_list)\n",
    "    f4_var = statistics.variance(f4_list)\n",
    "    \n",
    "    res['f0_mean'] = f0_mean\n",
    "    res['f1_mean'] = f1_mean\n",
    "    res['f2_mean'] = f2_mean\n",
    "    res['f3_mean'] = f3_mean\n",
    "    res['f4_mean'] = f4_mean\n",
    "    res['f1_median'] = f1_median\n",
    "    res['f2_median'] = f2_median\n",
    "    res['f3_median'] = f3_median\n",
    "    res['f4_median'] = f4_median\n",
    "    res['f0_var'] = f0_var\n",
    "    res['f1_var'] = f1_var\n",
    "    res['f2_var'] = f2_var\n",
    "    res['f3_var'] = f3_var\n",
    "    res['f4_var'] = f4_var\n",
    "\n",
    "    return res\n",
    "\n",
    "measureFormants(AUDIOS_DEVELOPMENT, audio_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTemporalMedian(dir, audio):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "    \n",
    "    res = pd.DataFrame(0.0, index=[audio_id], columns=['temporalMedian'])\n",
    "\n",
    "    s, sr = librosa.load(dir+audio, sr=sampling_rate)\n",
    "\n",
    "    med = maad.features.temporal_median(s)\n",
    "\n",
    "    res['temporalMedian'] = med\n",
    "\n",
    "    return res\n",
    "\n",
    "computeTemporalMedian(AUDIOS_DEVELOPMENT, audio_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEntropy(dir, audio):\n",
    "    audio_id = int(audio.split('.')[0])-1\n",
    "    \n",
    "    res = pd.DataFrame(0.0, index=[audio_id], columns=['temporal_entropy','frequence_entropy', 'mean_spectral_entropy'])\n",
    "\n",
    "    s, sr = librosa.load(dir+audio, sr=sampling_rate)\n",
    "    Ht = maad.features.temporal_entropy(s)\n",
    "\n",
    "    Sxx_power,tn,fn,_ = maad.sound.spectrogram(s, sr)   \n",
    "    Hf, Ht_per_bin = maad.features.frequency_entropy(Sxx_power)\n",
    "    EAS, ECU, ECV, EPS, EPS_KURT, EPS_SKEW = maad.features.spectral_entropy(Sxx_power, fn, flim=(2000,10000)) \n",
    "\n",
    "    res['temporal_entropy'] = Ht\n",
    "    res['frequence_entropy'] = Hf\n",
    "    res['mean_spectral_entropy'] = EAS\n",
    "\n",
    "    return res\n",
    "computeEntropy(AUDIOS_DEVELOPMENT, audio_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audios = np.random.choice(audio_dev, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features_for_single_audio(dir, audio, plot=False):\n",
    "    time = time_domain(dir, audio, plot)\n",
    "    freq = freq_domain(dir, audio, plot)\n",
    "    spec = spectrogram(dir, audio, plot)\n",
    "    mel = mel_spectrogram(dir, audio, plot)\n",
    "    mfccs = mfcc(dir, audio, plot)\n",
    "    # formant = measureFormants(dir, audio)\n",
    "\n",
    "    # make unique dataframe\n",
    "    features = pd.concat([time, freq, spec, mel, mfccs], axis=1)\n",
    "\n",
    "    features.index.name = 'audio_name'\n",
    "\n",
    "    return features   \n",
    "\n",
    "def extract_all_features(dir, audios, function, plot=False, n_jobs=-1):\n",
    "    # Parallelize the feature extraction for each audio\n",
    "    all_features = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(function)(dir, audio, plot) for audio in audios\n",
    "    )\n",
    "    \n",
    "    features = pd.concat(all_features)\n",
    "    features.index.name = 'audio_id'\n",
    "    \n",
    "    return features\n",
    "\n",
    "def calc_macro_set_of_features(func, dir, audios, njobs = 9, fout=None):\n",
    "    all_features = Parallel(n_jobs=njobs)(\n",
    "        delayed(func)(dir, file) for file in tqdm(audios)\n",
    "    )\n",
    "\n",
    "    funds = pd.concat(all_features)\n",
    "    funds.index.name = 'audio_id'\n",
    "\n",
    "    if fout is not None:\n",
    "        funds.to_csv(\"Features/dev/\"+fout)\n",
    "    \n",
    "    return funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:00<?, ?it/s]\n",
      "100%|| 3/3 [00:03<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_length</th>\n",
       "      <th>mean_absolute_slope</th>\n",
       "      <th>median_pitch_pm</th>\n",
       "      <th>median_pitch_strength</th>\n",
       "      <th>pitch_iqr</th>\n",
       "      <th>min_pitch_pm</th>\n",
       "      <th>max_pitch_pm</th>\n",
       "      <th>voiced_frames</th>\n",
       "      <th>number_of_frames</th>\n",
       "      <th>sm</th>\n",
       "      <th>...</th>\n",
       "      <th>f4_mean</th>\n",
       "      <th>f1_median</th>\n",
       "      <th>f2_median</th>\n",
       "      <th>f3_median</th>\n",
       "      <th>f4_median</th>\n",
       "      <th>f0_var</th>\n",
       "      <th>f1_var</th>\n",
       "      <th>f2_var</th>\n",
       "      <th>f3_var</th>\n",
       "      <th>f4_var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>35.695215</td>\n",
       "      <td>298.854983</td>\n",
       "      <td>206.228161</td>\n",
       "      <td>0.988962</td>\n",
       "      <td>17.241350</td>\n",
       "      <td>80.527911</td>\n",
       "      <td>599.452467</td>\n",
       "      <td>1604</td>\n",
       "      <td>3566</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>3834.482180</td>\n",
       "      <td>405.547694</td>\n",
       "      <td>1857.896614</td>\n",
       "      <td>2814.788673</td>\n",
       "      <td>3879.468629</td>\n",
       "      <td>1202.402426</td>\n",
       "      <td>39572.236908</td>\n",
       "      <td>245251.213989</td>\n",
       "      <td>59703.589045</td>\n",
       "      <td>141079.473162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>1.513146</td>\n",
       "      <td>462.903408</td>\n",
       "      <td>244.131745</td>\n",
       "      <td>0.958624</td>\n",
       "      <td>47.983624</td>\n",
       "      <td>190.822354</td>\n",
       "      <td>358.364385</td>\n",
       "      <td>131</td>\n",
       "      <td>148</td>\n",
       "      <td>-0.002962</td>\n",
       "      <td>...</td>\n",
       "      <td>3891.145846</td>\n",
       "      <td>385.542884</td>\n",
       "      <td>1631.960085</td>\n",
       "      <td>2820.224752</td>\n",
       "      <td>3907.512483</td>\n",
       "      <td>1696.421610</td>\n",
       "      <td>34043.083373</td>\n",
       "      <td>196448.177520</td>\n",
       "      <td>100591.134273</td>\n",
       "      <td>152056.750681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>2.722938</td>\n",
       "      <td>94.007351</td>\n",
       "      <td>94.717117</td>\n",
       "      <td>0.943951</td>\n",
       "      <td>10.491220</td>\n",
       "      <td>78.499557</td>\n",
       "      <td>111.540400</td>\n",
       "      <td>144</td>\n",
       "      <td>269</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>...</td>\n",
       "      <td>3496.468645</td>\n",
       "      <td>471.151072</td>\n",
       "      <td>1614.355505</td>\n",
       "      <td>2502.257430</td>\n",
       "      <td>3466.186914</td>\n",
       "      <td>54.556999</td>\n",
       "      <td>43627.072721</td>\n",
       "      <td>184232.829088</td>\n",
       "      <td>96228.115503</td>\n",
       "      <td>247729.800261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          audio_length  mean_absolute_slope  median_pitch_pm  \\\n",
       "audio_id                                                       \n",
       "1662         35.695215           298.854983       206.228161   \n",
       "2645          1.513146           462.903408       244.131745   \n",
       "2267          2.722938            94.007351        94.717117   \n",
       "\n",
       "          median_pitch_strength  pitch_iqr  min_pitch_pm  max_pitch_pm  \\\n",
       "audio_id                                                                 \n",
       "1662                   0.988962  17.241350     80.527911    599.452467   \n",
       "2645                   0.958624  47.983624    190.822354    358.364385   \n",
       "2267                   0.943951  10.491220     78.499557    111.540400   \n",
       "\n",
       "          voiced_frames  number_of_frames        sm  ...      f4_mean  \\\n",
       "audio_id                                             ...                \n",
       "1662               1604              3566 -0.000030  ...  3834.482180   \n",
       "2645                131               148 -0.002962  ...  3891.145846   \n",
       "2267                144               269 -0.002571  ...  3496.468645   \n",
       "\n",
       "           f1_median    f2_median    f3_median    f4_median       f0_var  \\\n",
       "audio_id                                                                   \n",
       "1662      405.547694  1857.896614  2814.788673  3879.468629  1202.402426   \n",
       "2645      385.542884  1631.960085  2820.224752  3907.512483  1696.421610   \n",
       "2267      471.151072  1614.355505  2502.257430  3466.186914    54.556999   \n",
       "\n",
       "                f1_var         f2_var         f3_var         f4_var  \n",
       "audio_id                                                             \n",
       "1662      39572.236908  245251.213989   59703.589045  141079.473162  \n",
       "2645      34043.083373  196448.177520  100591.134273  152056.750681  \n",
       "2267      43627.072721  184232.829088   96228.115503  247729.800261  \n",
       "\n",
       "[3 rows x 207 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat = calc_macro_set_of_features(extract_all_features_for_single_audio, AUDIOS_DEVELOPMENT, test_audios)\n",
    "formants = calc_macro_set_of_features(measureFormants, AUDIOS_DEVELOPMENT, test_audios, 1)\n",
    "\n",
    "display(pd.concat([feat, formants], axis=1))\n",
    "\n",
    "# calc_macro_set_of_features(extract_all_features_for_single_audio, AUDIOS_DEVELOPMENT, audio_dev)\n",
    "# calc_macro_set_of_features(extract_all_features_for_single_audio, AUDIOS_EVALUATION, audio_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(df, dir):\n",
    "    for file, columns in columns_correlator.items():\n",
    "        with open(dir+file, \"w\", newline='') as f:\n",
    "            res = df[columns]\n",
    "            res.to_csv(f)\n",
    "\n",
    "def load_features(dir, filter):\n",
    "    res = pd.DataFrame()\n",
    "\n",
    "    i = 0\n",
    "    for file, columns in columns_correlator.items():\n",
    "        if filter[i]:\n",
    "            with open(dir+file, \"r\") as f:\n",
    "                temp = pd.read_csv(f, header=0, index_col=0)\n",
    "                # display(temp)\n",
    "                res = pd.concat([res, temp[columns]], axis=1)\n",
    "        i +=1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_length</th>\n",
       "      <th>mean_absolute_slope</th>\n",
       "      <th>pitch_iqr</th>\n",
       "      <th>voiced_frames</th>\n",
       "      <th>number_of_frames</th>\n",
       "      <th>sm</th>\n",
       "      <th>sv</th>\n",
       "      <th>ss</th>\n",
       "      <th>sk</th>\n",
       "      <th>Time 5%</th>\n",
       "      <th>...</th>\n",
       "      <th>f4_mean</th>\n",
       "      <th>f0_var</th>\n",
       "      <th>f1_var</th>\n",
       "      <th>f2_var</th>\n",
       "      <th>f3_var</th>\n",
       "      <th>f4_var</th>\n",
       "      <th>temporalMedian</th>\n",
       "      <th>temporal_entropy</th>\n",
       "      <th>frequence_entropy</th>\n",
       "      <th>mean_spectral_entropy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.120522</td>\n",
       "      <td>301.742399</td>\n",
       "      <td>67.707652</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>3509.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>3509.0</td>\n",
       "      <td>21.173347</td>\n",
       "      <td>1.776327</td>\n",
       "      <td>...</td>\n",
       "      <td>3510.873206</td>\n",
       "      <td>2813.567191</td>\n",
       "      <td>34429.560045</td>\n",
       "      <td>219530.519863</td>\n",
       "      <td>151540.763589</td>\n",
       "      <td>208844.962303</td>\n",
       "      <td>0.046026</td>\n",
       "      <td>0.809055</td>\n",
       "      <td>0.718480</td>\n",
       "      <td>0.141662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.365420</td>\n",
       "      <td>317.851337</td>\n",
       "      <td>19.273885</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>7.998921</td>\n",
       "      <td>1.091338</td>\n",
       "      <td>...</td>\n",
       "      <td>3828.723579</td>\n",
       "      <td>2150.713517</td>\n",
       "      <td>39357.097794</td>\n",
       "      <td>211350.009803</td>\n",
       "      <td>69467.821193</td>\n",
       "      <td>297961.685446</td>\n",
       "      <td>0.112830</td>\n",
       "      <td>0.872433</td>\n",
       "      <td>0.529477</td>\n",
       "      <td>0.276642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.693583</td>\n",
       "      <td>438.466293</td>\n",
       "      <td>35.854312</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2166.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>2166.0</td>\n",
       "      <td>11.807234</td>\n",
       "      <td>0.952018</td>\n",
       "      <td>...</td>\n",
       "      <td>3622.444527</td>\n",
       "      <td>2385.674893</td>\n",
       "      <td>52124.778396</td>\n",
       "      <td>179737.307673</td>\n",
       "      <td>186931.222502</td>\n",
       "      <td>160443.939763</td>\n",
       "      <td>0.086232</td>\n",
       "      <td>0.873387</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.036861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.503379</td>\n",
       "      <td>301.677878</td>\n",
       "      <td>33.615390</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>6.205435</td>\n",
       "      <td>0.743039</td>\n",
       "      <td>...</td>\n",
       "      <td>3807.289843</td>\n",
       "      <td>2184.668438</td>\n",
       "      <td>23322.949636</td>\n",
       "      <td>362195.187865</td>\n",
       "      <td>196404.027958</td>\n",
       "      <td>437098.207268</td>\n",
       "      <td>0.283693</td>\n",
       "      <td>0.911091</td>\n",
       "      <td>0.593108</td>\n",
       "      <td>0.041106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.133583</td>\n",
       "      <td>463.564014</td>\n",
       "      <td>23.228543</td>\n",
       "      <td>965.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>8.035221</td>\n",
       "      <td>0.975238</td>\n",
       "      <td>...</td>\n",
       "      <td>3351.949804</td>\n",
       "      <td>5869.188076</td>\n",
       "      <td>174479.927981</td>\n",
       "      <td>291030.183898</td>\n",
       "      <td>76841.439908</td>\n",
       "      <td>116702.012325</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.887211</td>\n",
       "      <td>0.601885</td>\n",
       "      <td>0.216039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          audio_length  mean_absolute_slope  pitch_iqr  voiced_frames  \\\n",
       "audio_id                                                                \n",
       "0            35.120522           301.742399  67.707652         1584.0   \n",
       "1            23.365420           317.851337  19.273885         1271.0   \n",
       "2            21.693583           438.466293  35.854312         1093.0   \n",
       "3            22.503379           301.677878  33.615390         1377.0   \n",
       "4            19.133583           463.564014  23.228543          965.0   \n",
       "\n",
       "          number_of_frames        sm        sv      ss         sk   Time 5%  \\\n",
       "audio_id                                                                      \n",
       "0                   3509.0  0.000002  0.002254  3509.0  21.173347  1.776327   \n",
       "1                   2333.0  0.000028  0.007819  2333.0   7.998921  1.091338   \n",
       "2                   2166.0  0.000005  0.002974  2166.0  11.807234  0.952018   \n",
       "3                   2247.0  0.000011  0.022371  2247.0   6.205435  0.743039   \n",
       "4                   1910.0  0.000036  0.005369  1910.0   8.035221  0.975238   \n",
       "\n",
       "          ...      f4_mean       f0_var         f1_var         f2_var  \\\n",
       "audio_id  ...                                                           \n",
       "0         ...  3510.873206  2813.567191   34429.560045  219530.519863   \n",
       "1         ...  3828.723579  2150.713517   39357.097794  211350.009803   \n",
       "2         ...  3622.444527  2385.674893   52124.778396  179737.307673   \n",
       "3         ...  3807.289843  2184.668438   23322.949636  362195.187865   \n",
       "4         ...  3351.949804  5869.188076  174479.927981  291030.183898   \n",
       "\n",
       "                 f3_var         f4_var  temporalMedian  temporal_entropy  \\\n",
       "audio_id                                                                   \n",
       "0         151540.763589  208844.962303        0.046026          0.809055   \n",
       "1          69467.821193  297961.685446        0.112830          0.872433   \n",
       "2         186931.222502  160443.939763        0.086232          0.873387   \n",
       "3         196404.027958  437098.207268        0.283693          0.911091   \n",
       "4          76841.439908  116702.012325        0.122995          0.887211   \n",
       "\n",
       "          frequence_entropy  mean_spectral_entropy  \n",
       "audio_id                                            \n",
       "0                  0.718480               0.141662  \n",
       "1                  0.529477               0.276642  \n",
       "2                  0.601450               0.036861  \n",
       "3                  0.593108               0.041106  \n",
       "4                  0.601885               0.216039  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = [1,1,1,0,1,0,0,1,1,1,1] # BEST FOR NOW\n",
    "\n",
    "if COMPUTE_ALL_AUDIO_FEATURES:\n",
    "    features_extracted_dev = extract_all_features(AUDIOS_DEVELOPMENT, audio_dev, extract_all_features_for_single_audio, n_jobs=-1)\n",
    "    formants = calc_macro_set_of_features(measureFormants, AUDIOS_DEVELOPMENT, audio_dev, 1)\n",
    "    features_extracted_dev = pd.concat([features_extracted_dev, formants], axis=1)\n",
    "    \n",
    "    save_features(features_extracted_dev, 'Features/dev/')\n",
    "else:\n",
    "    features_extracted_dev = load_features('Features/dev/', filter)\n",
    "\n",
    "features_extracted_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_length</th>\n",
       "      <th>mean_absolute_slope</th>\n",
       "      <th>pitch_iqr</th>\n",
       "      <th>voiced_frames</th>\n",
       "      <th>number_of_frames</th>\n",
       "      <th>sm</th>\n",
       "      <th>sv</th>\n",
       "      <th>ss</th>\n",
       "      <th>sk</th>\n",
       "      <th>Time 5%</th>\n",
       "      <th>...</th>\n",
       "      <th>f4_mean</th>\n",
       "      <th>f0_var</th>\n",
       "      <th>f1_var</th>\n",
       "      <th>f2_var</th>\n",
       "      <th>f3_var</th>\n",
       "      <th>f4_var</th>\n",
       "      <th>temporalMedian</th>\n",
       "      <th>temporal_entropy</th>\n",
       "      <th>frequence_entropy</th>\n",
       "      <th>mean_spectral_entropy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.516440</td>\n",
       "      <td>921.705710</td>\n",
       "      <td>63.936996</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>3848.0</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>3848.0</td>\n",
       "      <td>9.252883</td>\n",
       "      <td>1.439637</td>\n",
       "      <td>...</td>\n",
       "      <td>3633.499481</td>\n",
       "      <td>14991.667516</td>\n",
       "      <td>230846.801084</td>\n",
       "      <td>293951.760598</td>\n",
       "      <td>222685.898201</td>\n",
       "      <td>239701.422606</td>\n",
       "      <td>0.055413</td>\n",
       "      <td>0.875688</td>\n",
       "      <td>0.621813</td>\n",
       "      <td>0.207001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.881338</td>\n",
       "      <td>399.566530</td>\n",
       "      <td>24.691080</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>3185.0</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>3185.0</td>\n",
       "      <td>7.460160</td>\n",
       "      <td>1.607982</td>\n",
       "      <td>...</td>\n",
       "      <td>3775.787727</td>\n",
       "      <td>4091.956598</td>\n",
       "      <td>123749.847934</td>\n",
       "      <td>241713.799259</td>\n",
       "      <td>128468.102711</td>\n",
       "      <td>131958.353156</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.897492</td>\n",
       "      <td>0.534788</td>\n",
       "      <td>0.038083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.405896</td>\n",
       "      <td>232.542158</td>\n",
       "      <td>18.473710</td>\n",
       "      <td>120.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-0.002472</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>237.0</td>\n",
       "      <td>9.731730</td>\n",
       "      <td>0.522449</td>\n",
       "      <td>...</td>\n",
       "      <td>3580.235967</td>\n",
       "      <td>5507.166839</td>\n",
       "      <td>35305.605441</td>\n",
       "      <td>105779.867349</td>\n",
       "      <td>21792.480911</td>\n",
       "      <td>68802.798671</td>\n",
       "      <td>0.120436</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.623284</td>\n",
       "      <td>0.095436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.724603</td>\n",
       "      <td>307.265975</td>\n",
       "      <td>20.545535</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>3169.0</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>3169.0</td>\n",
       "      <td>8.667985</td>\n",
       "      <td>2.768980</td>\n",
       "      <td>...</td>\n",
       "      <td>3604.242464</td>\n",
       "      <td>2883.108573</td>\n",
       "      <td>73738.064976</td>\n",
       "      <td>227771.655351</td>\n",
       "      <td>173806.710752</td>\n",
       "      <td>201813.860031</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>0.483658</td>\n",
       "      <td>0.137209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.056848</td>\n",
       "      <td>174.818941</td>\n",
       "      <td>35.425221</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>3302.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>3302.0</td>\n",
       "      <td>17.975306</td>\n",
       "      <td>1.904036</td>\n",
       "      <td>...</td>\n",
       "      <td>3546.798575</td>\n",
       "      <td>1490.867842</td>\n",
       "      <td>38154.399644</td>\n",
       "      <td>190827.738281</td>\n",
       "      <td>164592.622249</td>\n",
       "      <td>70389.473345</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.808132</td>\n",
       "      <td>0.714809</td>\n",
       "      <td>0.122580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>2.024479</td>\n",
       "      <td>453.071268</td>\n",
       "      <td>33.743017</td>\n",
       "      <td>115.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>-0.002556</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>199.0</td>\n",
       "      <td>6.764126</td>\n",
       "      <td>0.278639</td>\n",
       "      <td>...</td>\n",
       "      <td>3505.570583</td>\n",
       "      <td>333.602885</td>\n",
       "      <td>20529.306871</td>\n",
       "      <td>212834.450140</td>\n",
       "      <td>52343.191813</td>\n",
       "      <td>125368.827005</td>\n",
       "      <td>0.152787</td>\n",
       "      <td>0.872334</td>\n",
       "      <td>0.547930</td>\n",
       "      <td>0.044511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>4.947167</td>\n",
       "      <td>368.302588</td>\n",
       "      <td>17.812612</td>\n",
       "      <td>102.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>491.0</td>\n",
       "      <td>77.284744</td>\n",
       "      <td>2.316190</td>\n",
       "      <td>...</td>\n",
       "      <td>3547.952584</td>\n",
       "      <td>10635.493809</td>\n",
       "      <td>122041.756377</td>\n",
       "      <td>437955.462614</td>\n",
       "      <td>241631.472867</td>\n",
       "      <td>99525.772321</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.670537</td>\n",
       "      <td>0.561699</td>\n",
       "      <td>0.069291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>27.518889</td>\n",
       "      <td>519.059068</td>\n",
       "      <td>17.476003</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>8.121446</td>\n",
       "      <td>1.178413</td>\n",
       "      <td>...</td>\n",
       "      <td>3970.952506</td>\n",
       "      <td>2553.880838</td>\n",
       "      <td>61997.154886</td>\n",
       "      <td>263911.175237</td>\n",
       "      <td>122269.978455</td>\n",
       "      <td>188985.646375</td>\n",
       "      <td>0.150120</td>\n",
       "      <td>0.895597</td>\n",
       "      <td>0.497210</td>\n",
       "      <td>0.024357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>21.667460</td>\n",
       "      <td>330.130321</td>\n",
       "      <td>38.543050</td>\n",
       "      <td>979.0</td>\n",
       "      <td>2163.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>2163.0</td>\n",
       "      <td>14.955853</td>\n",
       "      <td>0.429569</td>\n",
       "      <td>...</td>\n",
       "      <td>3547.131822</td>\n",
       "      <td>2592.705772</td>\n",
       "      <td>72950.279609</td>\n",
       "      <td>225325.637550</td>\n",
       "      <td>77741.463624</td>\n",
       "      <td>82863.289129</td>\n",
       "      <td>0.105973</td>\n",
       "      <td>0.851720</td>\n",
       "      <td>0.764378</td>\n",
       "      <td>0.139938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1.262333</td>\n",
       "      <td>670.240124</td>\n",
       "      <td>12.969853</td>\n",
       "      <td>86.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>-0.002932</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>123.0</td>\n",
       "      <td>9.190891</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>...</td>\n",
       "      <td>3532.225732</td>\n",
       "      <td>114.583838</td>\n",
       "      <td>47784.874347</td>\n",
       "      <td>196557.026972</td>\n",
       "      <td>84855.708821</td>\n",
       "      <td>72610.157355</td>\n",
       "      <td>0.105571</td>\n",
       "      <td>0.809523</td>\n",
       "      <td>0.550065</td>\n",
       "      <td>0.065273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows  101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          audio_length  mean_absolute_slope  pitch_iqr  voiced_frames  \\\n",
       "audio_id                                                                \n",
       "0            38.516440           921.705710  63.936996         1875.0   \n",
       "1            31.881338           399.566530  24.691080         1696.0   \n",
       "2             2.405896           232.542158  18.473710          120.0   \n",
       "3            31.724603           307.265975  20.545535         1392.0   \n",
       "4            33.056848           174.818941  35.425221         1327.0   \n",
       "...                ...                  ...        ...            ...   \n",
       "686           2.024479           453.071268  33.743017          115.0   \n",
       "687           4.947167           368.302588  17.812612          102.0   \n",
       "688          27.518889           519.059068  17.476003         1492.0   \n",
       "689          21.667460           330.130321  38.543050          979.0   \n",
       "690           1.262333           670.240124  12.969853           86.0   \n",
       "\n",
       "          number_of_frames        sm        sv      ss         sk   Time 5%  \\\n",
       "audio_id                                                                      \n",
       "0                   3848.0 -0.000025  0.003136  3848.0   9.252883  1.439637   \n",
       "1                   3185.0 -0.000082  0.006783  3185.0   7.460160  1.607982   \n",
       "2                    237.0 -0.002472  0.004472   237.0   9.731730  0.522449   \n",
       "3                   3169.0 -0.000050  0.014893  3169.0   8.667985  2.768980   \n",
       "4                   3302.0  0.000002  0.001369  3302.0  17.975306  1.904036   \n",
       "...                    ...       ...       ...     ...        ...       ...   \n",
       "686                  199.0 -0.002556  0.004539   199.0   6.764126  0.278639   \n",
       "687                  491.0 -0.002524  0.000872   491.0  77.284744  2.316190   \n",
       "688                 2748.0 -0.000035  0.009148  2748.0   8.121446  1.178413   \n",
       "689                 2163.0  0.000004  0.003707  2163.0  14.955853  0.429569   \n",
       "690                  123.0 -0.002932  0.003361   123.0   9.190891  0.116100   \n",
       "\n",
       "          ...      f4_mean        f0_var         f1_var         f2_var  \\\n",
       "audio_id  ...                                                            \n",
       "0         ...  3633.499481  14991.667516  230846.801084  293951.760598   \n",
       "1         ...  3775.787727   4091.956598  123749.847934  241713.799259   \n",
       "2         ...  3580.235967   5507.166839   35305.605441  105779.867349   \n",
       "3         ...  3604.242464   2883.108573   73738.064976  227771.655351   \n",
       "4         ...  3546.798575   1490.867842   38154.399644  190827.738281   \n",
       "...       ...          ...           ...            ...            ...   \n",
       "686       ...  3505.570583    333.602885   20529.306871  212834.450140   \n",
       "687       ...  3547.952584  10635.493809  122041.756377  437955.462614   \n",
       "688       ...  3970.952506   2553.880838   61997.154886  263911.175237   \n",
       "689       ...  3547.131822   2592.705772   72950.279609  225325.637550   \n",
       "690       ...  3532.225732    114.583838   47784.874347  196557.026972   \n",
       "\n",
       "                 f3_var         f4_var  temporalMedian  temporal_entropy  \\\n",
       "audio_id                                                                   \n",
       "0         222685.898201  239701.422606        0.055413          0.875688   \n",
       "1         128468.102711  131958.353156        0.128515          0.897492   \n",
       "2          21792.480911   68802.798671        0.120436          0.829897   \n",
       "3         173806.710752  201813.860031        0.105894          0.866769   \n",
       "4         164592.622249   70389.473345        0.037209          0.808132   \n",
       "...                 ...            ...             ...               ...   \n",
       "686        52343.191813  125368.827005        0.152787          0.872334   \n",
       "687       241631.472867   99525.772321        0.011394          0.670537   \n",
       "688       122269.978455  188985.646375        0.150120          0.895597   \n",
       "689        77741.463624   82863.289129        0.105973          0.851720   \n",
       "690        84855.708821   72610.157355        0.105571          0.809523   \n",
       "\n",
       "          frequence_entropy  mean_spectral_entropy  \n",
       "audio_id                                            \n",
       "0                  0.621813               0.207001  \n",
       "1                  0.534788               0.038083  \n",
       "2                  0.623284               0.095436  \n",
       "3                  0.483658               0.137209  \n",
       "4                  0.714809               0.122580  \n",
       "...                     ...                    ...  \n",
       "686                0.547930               0.044511  \n",
       "687                0.561699               0.069291  \n",
       "688                0.497210               0.024357  \n",
       "689                0.764378               0.139938  \n",
       "690                0.550065               0.065273  \n",
       "\n",
       "[691 rows x 101 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if COMPUTE_ALL_AUDIO_FEATURES:\n",
    "    features_extracted_eval = extract_all_features(AUDIOS_EVALUATION, audio_eval, extract_all_features_for_single_audio, n_jobs=-1)\n",
    "    formants = calc_macro_set_of_features(measureFormants, AUDIOS_EVALUATION, audio_eval, 1)\n",
    "    features_extracted_eval = pd.concat([features_extracted_eval, formants], axis=1)\n",
    "\n",
    "    save_features(features_extracted_eval, 'Features/eval/')\n",
    "else:\n",
    "    features_extracted_eval = load_features('Features/eval/', filter)\n",
    "\n",
    "features_extracted_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>mean_pitch</th>\n",
       "      <th>max_pitch</th>\n",
       "      <th>min_pitch</th>\n",
       "      <th>jitter</th>\n",
       "      <th>shimmer</th>\n",
       "      <th>energy</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>f1_var</th>\n",
       "      <th>f2_var</th>\n",
       "      <th>f3_var</th>\n",
       "      <th>f4_var</th>\n",
       "      <th>temporalMedian</th>\n",
       "      <th>temporal_entropy</th>\n",
       "      <th>frequence_entropy</th>\n",
       "      <th>mean_spectral_entropy</th>\n",
       "      <th>char_per_second</th>\n",
       "      <th>words_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.260475</td>\n",
       "      <td>3999.7170</td>\n",
       "      <td>145.43066</td>\n",
       "      <td>-1.860294</td>\n",
       "      <td>-1.082361</td>\n",
       "      <td>-2.647084</td>\n",
       "      <td>-0.677588</td>\n",
       "      <td>3.493075</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>...</td>\n",
       "      <td>34429.560045</td>\n",
       "      <td>219530.519863</td>\n",
       "      <td>151540.763589</td>\n",
       "      <td>208844.962303</td>\n",
       "      <td>0.046026</td>\n",
       "      <td>0.809055</td>\n",
       "      <td>0.718480</td>\n",
       "      <td>0.141662</td>\n",
       "      <td>8.001020</td>\n",
       "      <td>1.964663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.113214</td>\n",
       "      <td>3998.8590</td>\n",
       "      <td>145.37268</td>\n",
       "      <td>-1.596048</td>\n",
       "      <td>-1.016633</td>\n",
       "      <td>-2.106869</td>\n",
       "      <td>-1.103202</td>\n",
       "      <td>3.227377</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>...</td>\n",
       "      <td>39357.097794</td>\n",
       "      <td>211350.009803</td>\n",
       "      <td>69467.821193</td>\n",
       "      <td>297961.685446</td>\n",
       "      <td>0.112830</td>\n",
       "      <td>0.872433</td>\n",
       "      <td>0.529477</td>\n",
       "      <td>0.276642</td>\n",
       "      <td>12.026319</td>\n",
       "      <td>2.953082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.124782</td>\n",
       "      <td>3998.8025</td>\n",
       "      <td>145.42395</td>\n",
       "      <td>-1.719708</td>\n",
       "      <td>-0.922792</td>\n",
       "      <td>-2.526618</td>\n",
       "      <td>-0.977303</td>\n",
       "      <td>3.411098</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>...</td>\n",
       "      <td>52124.778396</td>\n",
       "      <td>179737.307673</td>\n",
       "      <td>186931.222502</td>\n",
       "      <td>160443.939763</td>\n",
       "      <td>0.086232</td>\n",
       "      <td>0.873387</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.036861</td>\n",
       "      <td>12.953139</td>\n",
       "      <td>3.180664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.155442</td>\n",
       "      <td>3998.4510</td>\n",
       "      <td>147.98083</td>\n",
       "      <td>-1.769457</td>\n",
       "      <td>-0.989746</td>\n",
       "      <td>-1.650323</td>\n",
       "      <td>-0.760197</td>\n",
       "      <td>3.514515</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>...</td>\n",
       "      <td>23322.949636</td>\n",
       "      <td>362195.187865</td>\n",
       "      <td>196404.027958</td>\n",
       "      <td>437098.207268</td>\n",
       "      <td>0.283693</td>\n",
       "      <td>0.911091</td>\n",
       "      <td>0.593108</td>\n",
       "      <td>0.041106</td>\n",
       "      <td>12.487014</td>\n",
       "      <td>3.066206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.227559</td>\n",
       "      <td>3998.6113</td>\n",
       "      <td>145.44772</td>\n",
       "      <td>-1.552417</td>\n",
       "      <td>-0.903676</td>\n",
       "      <td>-2.270137</td>\n",
       "      <td>-0.969483</td>\n",
       "      <td>3.285759</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>...</td>\n",
       "      <td>174479.927981</td>\n",
       "      <td>291030.183898</td>\n",
       "      <td>76841.439908</td>\n",
       "      <td>116702.012325</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.887211</td>\n",
       "      <td>0.601885</td>\n",
       "      <td>0.216039</td>\n",
       "      <td>14.686220</td>\n",
       "      <td>3.606225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.215148</td>\n",
       "      <td>3999.1616</td>\n",
       "      <td>145.39359</td>\n",
       "      <td>-1.626217</td>\n",
       "      <td>-0.937941</td>\n",
       "      <td>-2.726145</td>\n",
       "      <td>-0.951563</td>\n",
       "      <td>3.340217</td>\n",
       "      <td>184.570312</td>\n",
       "      <td>...</td>\n",
       "      <td>66222.798915</td>\n",
       "      <td>175896.052135</td>\n",
       "      <td>130871.995575</td>\n",
       "      <td>90454.343479</td>\n",
       "      <td>0.084476</td>\n",
       "      <td>0.871634</td>\n",
       "      <td>0.681852</td>\n",
       "      <td>0.106307</td>\n",
       "      <td>13.747752</td>\n",
       "      <td>3.375783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.037267</td>\n",
       "      <td>3984.6550</td>\n",
       "      <td>145.58409</td>\n",
       "      <td>-1.814822</td>\n",
       "      <td>-0.897088</td>\n",
       "      <td>-3.469522</td>\n",
       "      <td>-1.151763</td>\n",
       "      <td>3.433348</td>\n",
       "      <td>83.354335</td>\n",
       "      <td>...</td>\n",
       "      <td>96990.580496</td>\n",
       "      <td>219754.064462</td>\n",
       "      <td>86074.806664</td>\n",
       "      <td>175899.607301</td>\n",
       "      <td>0.031989</td>\n",
       "      <td>0.824046</td>\n",
       "      <td>0.622742</td>\n",
       "      <td>0.103284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.997589</td>\n",
       "      <td>3989.1785</td>\n",
       "      <td>148.97475</td>\n",
       "      <td>-2.014281</td>\n",
       "      <td>-0.984913</td>\n",
       "      <td>-2.834494</td>\n",
       "      <td>-1.233272</td>\n",
       "      <td>3.351931</td>\n",
       "      <td>89.102909</td>\n",
       "      <td>...</td>\n",
       "      <td>22566.575091</td>\n",
       "      <td>376372.131589</td>\n",
       "      <td>65539.031340</td>\n",
       "      <td>64229.155642</td>\n",
       "      <td>0.048325</td>\n",
       "      <td>0.781826</td>\n",
       "      <td>0.566879</td>\n",
       "      <td>0.181915</td>\n",
       "      <td>5.471125</td>\n",
       "      <td>0.607903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.204122</td>\n",
       "      <td>3999.7559</td>\n",
       "      <td>145.36101</td>\n",
       "      <td>-1.708386</td>\n",
       "      <td>-0.995910</td>\n",
       "      <td>-2.351544</td>\n",
       "      <td>-0.938779</td>\n",
       "      <td>3.263541</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>...</td>\n",
       "      <td>9717.543069</td>\n",
       "      <td>94965.755023</td>\n",
       "      <td>53117.662147</td>\n",
       "      <td>104763.363990</td>\n",
       "      <td>0.090937</td>\n",
       "      <td>0.862373</td>\n",
       "      <td>0.539205</td>\n",
       "      <td>0.193632</td>\n",
       "      <td>13.540097</td>\n",
       "      <td>3.324793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.839026</td>\n",
       "      <td>3988.2874</td>\n",
       "      <td>149.26643</td>\n",
       "      <td>-1.828768</td>\n",
       "      <td>-1.016969</td>\n",
       "      <td>-2.434784</td>\n",
       "      <td>-1.375377</td>\n",
       "      <td>3.158431</td>\n",
       "      <td>83.354335</td>\n",
       "      <td>...</td>\n",
       "      <td>55287.130547</td>\n",
       "      <td>112737.778151</td>\n",
       "      <td>95637.909207</td>\n",
       "      <td>56050.373246</td>\n",
       "      <td>0.059501</td>\n",
       "      <td>0.766804</td>\n",
       "      <td>0.474520</td>\n",
       "      <td>0.151780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2933 rows  118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  mean_pitch  max_pitch  min_pitch    jitter   shimmer    energy  \\\n",
       "0       -1.0    3.260475  3999.7170  145.43066 -1.860294 -1.082361 -2.647084   \n",
       "1       -1.0    3.113214  3998.8590  145.37268 -1.596048 -1.016633 -2.106869   \n",
       "2       -1.0    3.124782  3998.8025  145.42395 -1.719708 -0.922792 -2.526618   \n",
       "3       -1.0    3.155442  3998.4510  147.98083 -1.769457 -0.989746 -1.650323   \n",
       "4        1.0    3.227559  3998.6113  145.44772 -1.552417 -0.903676 -2.270137   \n",
       "...      ...         ...        ...        ...       ...       ...       ...   \n",
       "2928     1.0    3.215148  3999.1616  145.39359 -1.626217 -0.937941 -2.726145   \n",
       "2929    -1.0    3.037267  3984.6550  145.58409 -1.814822 -0.897088 -3.469522   \n",
       "2930    -1.0    2.997589  3989.1785  148.97475 -2.014281 -0.984913 -2.834494   \n",
       "2931     1.0    3.204122  3999.7559  145.36101 -1.708386 -0.995910 -2.351544   \n",
       "2932    -1.0    2.839026  3988.2874  149.26643 -1.828768 -1.016969 -2.434784   \n",
       "\n",
       "      zcr_mean  spectral_centroid_mean       tempo  ...         f1_var  \\\n",
       "0    -0.677588                3.493075  151.999081  ...   34429.560045   \n",
       "1    -1.103202                3.227377  129.199219  ...   39357.097794   \n",
       "2    -0.977303                3.411098  117.453835  ...   52124.778396   \n",
       "3    -0.760197                3.514515  117.453835  ...   23322.949636   \n",
       "4    -0.969483                3.285759  112.347147  ...  174479.927981   \n",
       "...        ...                     ...         ...  ...            ...   \n",
       "2928 -0.951563                3.340217  184.570312  ...   66222.798915   \n",
       "2929 -1.151763                3.433348   83.354335  ...   96990.580496   \n",
       "2930 -1.233272                3.351931   89.102909  ...   22566.575091   \n",
       "2931 -0.938779                3.263541  143.554688  ...    9717.543069   \n",
       "2932 -1.375377                3.158431   83.354335  ...   55287.130547   \n",
       "\n",
       "             f2_var         f3_var         f4_var  temporalMedian  \\\n",
       "0     219530.519863  151540.763589  208844.962303        0.046026   \n",
       "1     211350.009803   69467.821193  297961.685446        0.112830   \n",
       "2     179737.307673  186931.222502  160443.939763        0.086232   \n",
       "3     362195.187865  196404.027958  437098.207268        0.283693   \n",
       "4     291030.183898   76841.439908  116702.012325        0.122995   \n",
       "...             ...            ...            ...             ...   \n",
       "2928  175896.052135  130871.995575   90454.343479        0.084476   \n",
       "2929  219754.064462   86074.806664  175899.607301        0.031989   \n",
       "2930  376372.131589   65539.031340   64229.155642        0.048325   \n",
       "2931   94965.755023   53117.662147  104763.363990        0.090937   \n",
       "2932  112737.778151   95637.909207   56050.373246        0.059501   \n",
       "\n",
       "      temporal_entropy  frequence_entropy  mean_spectral_entropy  \\\n",
       "0             0.809055           0.718480               0.141662   \n",
       "1             0.872433           0.529477               0.276642   \n",
       "2             0.873387           0.601450               0.036861   \n",
       "3             0.911091           0.593108               0.041106   \n",
       "4             0.887211           0.601885               0.216039   \n",
       "...                ...                ...                    ...   \n",
       "2928          0.871634           0.681852               0.106307   \n",
       "2929          0.824046           0.622742               0.103284   \n",
       "2930          0.781826           0.566879               0.181915   \n",
       "2931          0.862373           0.539205               0.193632   \n",
       "2932          0.766804           0.474520               0.151780   \n",
       "\n",
       "      char_per_second  words_per_second  \n",
       "0            8.001020          1.964663  \n",
       "1           12.026319          2.953082  \n",
       "2           12.953139          3.180664  \n",
       "3           12.487014          3.066206  \n",
       "4           14.686220          3.606225  \n",
       "...               ...               ...  \n",
       "2928        13.747752          3.375783  \n",
       "2929         0.000000          0.000000  \n",
       "2930         5.471125          0.607903  \n",
       "2931        13.540097          3.324793  \n",
       "2932         0.000000          0.000000  \n",
       "\n",
       "[2933 rows x 118 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>mean_pitch</th>\n",
       "      <th>max_pitch</th>\n",
       "      <th>min_pitch</th>\n",
       "      <th>jitter</th>\n",
       "      <th>shimmer</th>\n",
       "      <th>energy</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>f1_var</th>\n",
       "      <th>f2_var</th>\n",
       "      <th>f3_var</th>\n",
       "      <th>f4_var</th>\n",
       "      <th>temporalMedian</th>\n",
       "      <th>temporal_entropy</th>\n",
       "      <th>frequence_entropy</th>\n",
       "      <th>mean_spectral_entropy</th>\n",
       "      <th>char_per_second</th>\n",
       "      <th>words_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.024041</td>\n",
       "      <td>3945.1610</td>\n",
       "      <td>145.38750</td>\n",
       "      <td>-1.655967</td>\n",
       "      <td>-0.766810</td>\n",
       "      <td>-2.503650</td>\n",
       "      <td>-1.481972</td>\n",
       "      <td>3.190222</td>\n",
       "      <td>80.749512</td>\n",
       "      <td>...</td>\n",
       "      <td>230846.801084</td>\n",
       "      <td>293951.760598</td>\n",
       "      <td>222685.898201</td>\n",
       "      <td>239701.422606</td>\n",
       "      <td>0.055413</td>\n",
       "      <td>0.875688</td>\n",
       "      <td>0.621813</td>\n",
       "      <td>0.207001</td>\n",
       "      <td>7.295586</td>\n",
       "      <td>1.791443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.090556</td>\n",
       "      <td>3999.1720</td>\n",
       "      <td>145.56432</td>\n",
       "      <td>-1.575595</td>\n",
       "      <td>-0.877504</td>\n",
       "      <td>-2.168559</td>\n",
       "      <td>-0.906948</td>\n",
       "      <td>3.370109</td>\n",
       "      <td>89.102909</td>\n",
       "      <td>...</td>\n",
       "      <td>123749.847934</td>\n",
       "      <td>241713.799259</td>\n",
       "      <td>128468.102711</td>\n",
       "      <td>131958.353156</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.897492</td>\n",
       "      <td>0.534788</td>\n",
       "      <td>0.038083</td>\n",
       "      <td>8.813934</td>\n",
       "      <td>2.164276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.981497</td>\n",
       "      <td>3445.4490</td>\n",
       "      <td>145.67374</td>\n",
       "      <td>-1.743677</td>\n",
       "      <td>-1.016421</td>\n",
       "      <td>-2.348884</td>\n",
       "      <td>-1.049884</td>\n",
       "      <td>3.287707</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>...</td>\n",
       "      <td>35305.605441</td>\n",
       "      <td>105779.867349</td>\n",
       "      <td>21792.480911</td>\n",
       "      <td>68802.798671</td>\n",
       "      <td>0.120436</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.623284</td>\n",
       "      <td>0.095436</td>\n",
       "      <td>9.144203</td>\n",
       "      <td>2.493874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.145054</td>\n",
       "      <td>3998.8948</td>\n",
       "      <td>145.41223</td>\n",
       "      <td>-1.563995</td>\n",
       "      <td>-1.051092</td>\n",
       "      <td>-1.827025</td>\n",
       "      <td>-1.012987</td>\n",
       "      <td>3.262939</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>...</td>\n",
       "      <td>73738.064976</td>\n",
       "      <td>227771.655351</td>\n",
       "      <td>173806.710752</td>\n",
       "      <td>201813.860031</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>0.483658</td>\n",
       "      <td>0.137209</td>\n",
       "      <td>8.857479</td>\n",
       "      <td>2.174968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.213217</td>\n",
       "      <td>3999.7632</td>\n",
       "      <td>145.36313</td>\n",
       "      <td>-1.665122</td>\n",
       "      <td>-0.983571</td>\n",
       "      <td>-2.863526</td>\n",
       "      <td>-0.850934</td>\n",
       "      <td>3.403911</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>...</td>\n",
       "      <td>38154.399644</td>\n",
       "      <td>190827.738281</td>\n",
       "      <td>164592.622249</td>\n",
       "      <td>70389.473345</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.808132</td>\n",
       "      <td>0.714809</td>\n",
       "      <td>0.122580</td>\n",
       "      <td>8.500508</td>\n",
       "      <td>2.087313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.756353</td>\n",
       "      <td>3900.6730</td>\n",
       "      <td>145.67577</td>\n",
       "      <td>-1.724879</td>\n",
       "      <td>-1.101292</td>\n",
       "      <td>-2.342433</td>\n",
       "      <td>-1.142170</td>\n",
       "      <td>3.289255</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>...</td>\n",
       "      <td>20529.306871</td>\n",
       "      <td>212834.450140</td>\n",
       "      <td>52343.191813</td>\n",
       "      <td>125368.827005</td>\n",
       "      <td>0.152787</td>\n",
       "      <td>0.872334</td>\n",
       "      <td>0.547930</td>\n",
       "      <td>0.044511</td>\n",
       "      <td>7.409313</td>\n",
       "      <td>2.963725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.988621</td>\n",
       "      <td>3919.0024</td>\n",
       "      <td>145.90408</td>\n",
       "      <td>-1.613191</td>\n",
       "      <td>-0.929993</td>\n",
       "      <td>-3.056504</td>\n",
       "      <td>-1.114075</td>\n",
       "      <td>3.521088</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>...</td>\n",
       "      <td>122041.756377</td>\n",
       "      <td>437955.462614</td>\n",
       "      <td>241631.472867</td>\n",
       "      <td>99525.772321</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.670537</td>\n",
       "      <td>0.561699</td>\n",
       "      <td>0.069291</td>\n",
       "      <td>4.446990</td>\n",
       "      <td>1.414951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.046603</td>\n",
       "      <td>3999.3510</td>\n",
       "      <td>145.38307</td>\n",
       "      <td>-1.685346</td>\n",
       "      <td>-1.048880</td>\n",
       "      <td>-2.038675</td>\n",
       "      <td>-1.019482</td>\n",
       "      <td>3.295155</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>...</td>\n",
       "      <td>61997.154886</td>\n",
       "      <td>263911.175237</td>\n",
       "      <td>122269.978455</td>\n",
       "      <td>188985.646375</td>\n",
       "      <td>0.150120</td>\n",
       "      <td>0.895597</td>\n",
       "      <td>0.497210</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>10.211168</td>\n",
       "      <td>2.507369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.245309</td>\n",
       "      <td>3999.4610</td>\n",
       "      <td>145.56773</td>\n",
       "      <td>-1.583061</td>\n",
       "      <td>-0.972941</td>\n",
       "      <td>-2.430977</td>\n",
       "      <td>-0.849324</td>\n",
       "      <td>3.329910</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>...</td>\n",
       "      <td>72950.279609</td>\n",
       "      <td>225325.637550</td>\n",
       "      <td>77741.463624</td>\n",
       "      <td>82863.289129</td>\n",
       "      <td>0.105973</td>\n",
       "      <td>0.851720</td>\n",
       "      <td>0.764378</td>\n",
       "      <td>0.139938</td>\n",
       "      <td>12.968756</td>\n",
       "      <td>3.184499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.891838</td>\n",
       "      <td>3972.4630</td>\n",
       "      <td>147.44424</td>\n",
       "      <td>-1.960521</td>\n",
       "      <td>-0.966119</td>\n",
       "      <td>-2.472374</td>\n",
       "      <td>-1.078103</td>\n",
       "      <td>3.403169</td>\n",
       "      <td>184.570312</td>\n",
       "      <td>...</td>\n",
       "      <td>47784.874347</td>\n",
       "      <td>196557.026972</td>\n",
       "      <td>84855.708821</td>\n",
       "      <td>72610.157355</td>\n",
       "      <td>0.105571</td>\n",
       "      <td>0.809523</td>\n",
       "      <td>0.550065</td>\n",
       "      <td>0.065273</td>\n",
       "      <td>15.051492</td>\n",
       "      <td>3.960919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows  118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  mean_pitch  max_pitch  min_pitch    jitter   shimmer    energy  \\\n",
       "0       1.0    3.024041  3945.1610  145.38750 -1.655967 -0.766810 -2.503650   \n",
       "1       1.0    3.090556  3999.1720  145.56432 -1.575595 -0.877504 -2.168559   \n",
       "2       1.0    2.981497  3445.4490  145.67374 -1.743677 -1.016421 -2.348884   \n",
       "3      -1.0    3.145054  3998.8948  145.41223 -1.563995 -1.051092 -1.827025   \n",
       "4       1.0    3.213217  3999.7632  145.36313 -1.665122 -0.983571 -2.863526   \n",
       "..      ...         ...        ...        ...       ...       ...       ...   \n",
       "686     1.0    2.756353  3900.6730  145.67577 -1.724879 -1.101292 -2.342433   \n",
       "687     1.0    2.988621  3919.0024  145.90408 -1.613191 -0.929993 -3.056504   \n",
       "688    -1.0    3.046603  3999.3510  145.38307 -1.685346 -1.048880 -2.038675   \n",
       "689     1.0    3.245309  3999.4610  145.56773 -1.583061 -0.972941 -2.430977   \n",
       "690     1.0    2.891838  3972.4630  147.44424 -1.960521 -0.966119 -2.472374   \n",
       "\n",
       "     zcr_mean  spectral_centroid_mean       tempo  ...         f1_var  \\\n",
       "0   -1.481972                3.190222   80.749512  ...  230846.801084   \n",
       "1   -0.906948                3.370109   89.102909  ...  123749.847934   \n",
       "2   -1.049884                3.287707  123.046875  ...   35305.605441   \n",
       "3   -1.012987                3.262939  123.046875  ...   73738.064976   \n",
       "4   -0.850934                3.403911  112.347147  ...   38154.399644   \n",
       "..        ...                     ...         ...  ...            ...   \n",
       "686 -1.142170                3.289255  112.347147  ...   20529.306871   \n",
       "687 -1.114075                3.521088  112.347147  ...  122041.756377   \n",
       "688 -1.019482                3.295155  112.347147  ...   61997.154886   \n",
       "689 -0.849324                3.329910  117.453835  ...   72950.279609   \n",
       "690 -1.078103                3.403169  184.570312  ...   47784.874347   \n",
       "\n",
       "            f2_var         f3_var         f4_var  temporalMedian  \\\n",
       "0    293951.760598  222685.898201  239701.422606        0.055413   \n",
       "1    241713.799259  128468.102711  131958.353156        0.128515   \n",
       "2    105779.867349   21792.480911   68802.798671        0.120436   \n",
       "3    227771.655351  173806.710752  201813.860031        0.105894   \n",
       "4    190827.738281  164592.622249   70389.473345        0.037209   \n",
       "..             ...            ...            ...             ...   \n",
       "686  212834.450140   52343.191813  125368.827005        0.152787   \n",
       "687  437955.462614  241631.472867   99525.772321        0.011394   \n",
       "688  263911.175237  122269.978455  188985.646375        0.150120   \n",
       "689  225325.637550   77741.463624   82863.289129        0.105973   \n",
       "690  196557.026972   84855.708821   72610.157355        0.105571   \n",
       "\n",
       "     temporal_entropy  frequence_entropy  mean_spectral_entropy  \\\n",
       "0            0.875688           0.621813               0.207001   \n",
       "1            0.897492           0.534788               0.038083   \n",
       "2            0.829897           0.623284               0.095436   \n",
       "3            0.866769           0.483658               0.137209   \n",
       "4            0.808132           0.714809               0.122580   \n",
       "..                ...                ...                    ...   \n",
       "686          0.872334           0.547930               0.044511   \n",
       "687          0.670537           0.561699               0.069291   \n",
       "688          0.895597           0.497210               0.024357   \n",
       "689          0.851720           0.764378               0.139938   \n",
       "690          0.809523           0.550065               0.065273   \n",
       "\n",
       "     char_per_second  words_per_second  \n",
       "0           7.295586          1.791443  \n",
       "1           8.813934          2.164276  \n",
       "2           9.144203          2.493874  \n",
       "3           8.857479          2.174968  \n",
       "4           8.500508          2.087313  \n",
       "..               ...               ...  \n",
       "686         7.409313          2.963725  \n",
       "687         4.446990          1.414951  \n",
       "688        10.211168          2.507369  \n",
       "689        12.968756          3.184499  \n",
       "690        15.051492          3.960919  \n",
       "\n",
       "[691 rows x 118 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'mean_pitch', 'max_pitch', 'min_pitch', 'jitter', 'shimmer',\n",
       "       'energy', 'zcr_mean', 'spectral_centroid_mean', 'tempo',\n",
       "       ...\n",
       "       'f1_var', 'f2_var', 'f3_var', 'f4_var', 'temporalMedian',\n",
       "       'temporal_entropy', 'frequence_entropy', 'mean_spectral_entropy',\n",
       "       'char_per_second', 'words_per_second'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step4_dev_df = pd.concat([no_age_dev_df, features_extracted_dev], axis=1)\n",
    "step4_eval_df = pd.concat([step3_log_eval_df, features_extracted_eval], axis=1)\n",
    "\n",
    "step4_dev_df['char_per_second'] = step4_dev_df['num_characters'] / step4_dev_df['audio_length']\n",
    "step4_eval_df['char_per_second'] = step4_eval_df['num_characters'] / step4_eval_df['audio_length']\n",
    "\n",
    "step4_dev_df['words_per_second'] = step4_dev_df['num_words'] / step4_dev_df['audio_length']\n",
    "step4_eval_df['words_per_second'] = step4_eval_df['num_words'] / step4_eval_df['audio_length']\n",
    "\n",
    "# step4_dev_df = step4_dev_df.drop(columns=['num_characters', 'num_words', 'tempo', 'energy'], axis=1)\n",
    "# step4_eval_df = step4_eval_df.drop(columns=['num_characters', 'num_words', 'tempo', 'energy'], axis=1)\n",
    "\n",
    "display(step4_dev_df)\n",
    "display(step4_eval_df)\n",
    "display(step4_dev_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard scaling again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_join = StandardScaler().fit(step4_dev_df)\n",
    "\n",
    "step4_dev_norm_df = pd.DataFrame(scaler_join.transform(step4_dev_df), columns=step4_dev_df.columns)\n",
    "step4_eval_norm_df = pd.DataFrame(scaler_join.transform(step4_eval_df), columns=step4_eval_df.columns)\n",
    "\n",
    "display(step4_dev_norm_df.head())\n",
    "display(step4_eval_norm_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = PrettyTable(['Model', 'RMSE'])\n",
    "X_train_val_df = step4_dev_norm_df.copy()\n",
    "\n",
    "for model,name in zip(models, names):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    t.add_row([name, root_mean_squared_error(y_val, y_pred)])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_df = step4_dev_norm_df.copy()\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=100, n_jobs=9, random_state=341967)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest.predict(X_val)\n",
    "\n",
    "display(root_mean_squared_error(y_val, y_pred))\n",
    "\n",
    "_ = plot_error_distripution(y_pred, y_val, 0)\n",
    "# 10.377581109938676"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our own regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_tfr = TripleForestWithGenderDivision(\n",
    "    {\n",
    "        'n_estimators': 300,\n",
    "        'n_jobs': 9,\n",
    "        'random_state': 341967\n",
    "    },\n",
    "    {\n",
    "        'n_estimators': 300,\n",
    "        'n_jobs': 9,\n",
    "        'random_state': 341967\n",
    "    },\n",
    "    {\n",
    "        'n_estimators': 300,\n",
    "        'n_jobs': 9,\n",
    "        'random_state': 341967\n",
    "    },\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(step4_dev_norm_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "another_tfr.fit(X_train, y_train)\n",
    "y_pred = another_tfr.predict(X_val)\n",
    "\n",
    "display(root_mean_squared_error(y_val, y_pred))\n",
    "\n",
    "_ = plot_error_distripution(y_pred.values, y_val, 0)\n",
    "\n",
    "another_tfr.fit(step4_dev_norm_df, ages_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = another_tfr.predict(step4_eval_norm_df)\n",
    "\n",
    "with open(\"results.csv\", \"w\") as fout:\n",
    "    fout.write(\"Id,Predicted\\n\")\n",
    " \n",
    "    for id, y in enumerate(y_eval_pred):\n",
    "        fout.write(f\"{id},{y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfr_fine_tuning():\n",
    "    full_param_grid = {\n",
    "        'n_estimators': [300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'random_state': [341967]\n",
    "    }\n",
    "\n",
    "    male_param_grid = {\n",
    "        'n_estimators': [300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'random_state': [341967]\n",
    "    }\n",
    "\n",
    "    female_param_grid = {\n",
    "        'n_estimators': [300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'random_state': [341967]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=TripleForestWithGenderDivision(), \n",
    "        param_grid=CombinationHyperParameters(\n",
    "            full_param_grid, \n",
    "            male_param_grid, \n",
    "            female_param_grid\n",
    "        ).generate(), \n",
    "        cv=5, \n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=9\n",
    "    )\n",
    "\n",
    "    grid_search.fit(step4_dev_norm_df, ages_df)\n",
    "\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    best_tfr = grid_search.best_estimator_\n",
    "    test_score = best_tfr.score(step4_dev_norm_df, ages_df)\n",
    "    print(\"Test Accuracy:\", test_score)\n",
    "\n",
    "    return best_tfr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=TripleForestWithGenderDivision(), \n",
    "    param_grid=CombinationHyperParameters(\n",
    "        {'n_estimators': [500], 'max_depth': [10], 'min_samples_split': [10], 'min_samples_leaf': [2], 'random_state': [341967], 'n_jobs': [9]}, \n",
    "        {'n_estimators': [500], 'max_depth': [None], 'min_samples_split': [2], 'min_samples_leaf': [4], 'random_state': [341967], 'n_jobs': [9]}, \n",
    "        {'n_estimators': [500], 'max_depth': [10], 'min_samples_split': [5], 'min_samples_leaf': [1], 'random_state': [341967], 'n_jobs': [9]}\n",
    "        ).generate(), \n",
    "    cv=5, scoring='neg_root_mean_squared_error', n_jobs=9)\n",
    "\n",
    "grid_search.fit(step4_dev_norm_df, ages_df)\n",
    "\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "best_tfr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(step4_dev_norm_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "y_pred = best_tfr.predict(X_val)\n",
    "\n",
    "display(root_mean_squared_error(y_val, y_pred))\n",
    "\n",
    "_ = plot_error_distripution(y_pred.values, y_val, 0)\n",
    "# 9.60961532998382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_df = step4_dev_norm_df.copy()\n",
    "\n",
    "hist = HistGradientBoostingRegressor(random_state=341967, categorical_features=X_train_val_df.dtypes == 'object')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val_df, ages_df, test_size=0.2, shuffle=True, random_state=341967)\n",
    "\n",
    "hist.fit(X_train, y_train)\n",
    "y_pred = hist.predict(X_val)\n",
    "\n",
    "display(root_mean_squared_error(y_val, y_pred))\n",
    "\n",
    "_ = plot_error_distripution(y_pred, y_val, 0)\n",
    "# 9.916223846607522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.csv\", \"w\") as fout:\n",
    "    fout.write(\"Id,Predicted\\n\")\n",
    " \n",
    "    for id, y in enumerate(best_tfr.predict(step4_eval_norm_df)):\n",
    "        fout.write(f\"{id},{y}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
